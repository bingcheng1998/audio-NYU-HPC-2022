{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import OpencpopDataset, MusicLoaderGenerator\n",
    "from helper import parser_line, merge_note, get_pitch_labels, get_transposed_phoneme_labels, print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_transform(sample, sample_rate=None):\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(sample['text'])\n",
    "    text_with_p, phoneme, note, note_duration, slur_note = merge_note(text, phoneme, note, note_duration, slur_note)\n",
    "    sample['chinese'] = text_with_p\n",
    "    sample['phoneme'] = phoneme\n",
    "    sample['note'] = note\n",
    "    sample['duration'] = note_duration\n",
    "    sample['slur'] = slur_note\n",
    "    return sample\n",
    "\n",
    "dataset = OpencpopDataset('/scratch/bh2283/data/opencpop/segments/', transform=dataset_transform, sample_rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3744, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = dataset.split()\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 3744 test_set: 12\n",
      "['只', '有', '点', '遗', '憾', '难', '过', 'SP', 'AP', 'SP', '你', 'SP', '的', 'SP', '崩', '溃', '在', '~', '窗', '外', '零', '碎', 'SP', 'AP', 'SP']\n",
      "torch.Size([25, 2])\n",
      "torch.Size([25, 2])\n",
      "torch.Size([25])\n",
      "torch.Size([25, 80, 51])\n",
      "torch.Size([25]) tensor([31, 31, 16, 25, 28, 28, 33,  5, 28,  6, 41,  3, 34,  5, 34, 39, 20, 18,\n",
      "        47, 40, 28, 51,  3, 26,  4])\n"
     ]
    }
   ],
   "source": [
    "note_labels = get_pitch_labels()\n",
    "phoneme_labels = get_transposed_phoneme_labels()\n",
    "slur_labels = [0, 1]\n",
    "# 0-1 分辨率0.01，1-2 分辨率0.05，2-7 分辨率0.2\n",
    "duration_labels = [i for i in range(7)]\n",
    "\n",
    "labels = (\n",
    "    phoneme_labels,\n",
    "    note_labels,\n",
    "    duration_labels,\n",
    "    slur_labels\n",
    ")\n",
    "loaderGenerator = MusicLoaderGenerator(labels)\n",
    "train_loader = loaderGenerator.dataloader(train_set, batch_size=2)\n",
    "print('train_set:', len(train_set), 'test_set:',len(test_set))\n",
    "steps = 1\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    if steps <= 0:\n",
    "        break\n",
    "\n",
    "    print(sample_batched['chinese'])\n",
    "    print(sample_batched['phoneme'].shape)\n",
    "    print(sample_batched['phoneme_pre'].shape)\n",
    "    print(sample_batched['note_post'].shape)\n",
    "    print(sample_batched['mel'].shape)\n",
    "    print(sample_batched['mel_len'].shape, sample_batched['mel_len'])\n",
    "    steps -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 设计\n",
    "\n",
    "- 尝试使用逆卷积，上采样得到所需的音频\n",
    "- 我们无需去计算时间停止符，只需要在输出的时间内计算loss并且最小化即可\n",
    "- 设定一个最大时间长度，比如两秒，超过的就不要了（用阈值筛掉）\n",
    "- 多层上采样得到最佳的输出\n",
    "- 使用梅尔频谱，还有解码器，可以使得输出音质比stft好（猜的，需要验证）一般机器学习声码器都会好点\n",
    "\n",
    "但是有问题：\n",
    "- 使用逆卷积太过刚直，没有变化性，导致无法很好的收敛\n",
    "- 一般逆卷积和GAN一起使用，用判别器取代刚直的loss\n",
    "- 使用tacotron模式就会好很多，无需GAN，自收敛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.models.tacotron2 import Tacotron2, _get_mask_from_lengths, _Decoder, _Encoder, _Postnet\n",
    "from torchaudio.pipelines._tts.utils import _get_taco_params\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Tuple, List, Optional, Union, overload\n",
    "\n",
    "class TacotronTail(Tacotron2):\n",
    "    def __init__(\n",
    "        self,\n",
    "        labels_list,\n",
    "        decoder = None,\n",
    "        postnet = None,\n",
    "    ) -> None:\n",
    "        _tacotron2_params=_get_taco_params(n_symbols=len(labels_list)) # ignore n_symbols, encoder not used \n",
    "        super().__init__(**_tacotron2_params)\n",
    "\n",
    "        embedding_dim = _tacotron2_params['encoder_embedding_dim']\n",
    "        self.embeddings = [\n",
    "            torch.nn.Embedding(len(labals), embedding_dim)\n",
    "            for labals in labels_list\n",
    "        ]\n",
    "        \n",
    "        if decoder is not None:\n",
    "            self.decoder: _Decoder = decoder\n",
    "        if postnet is not None:\n",
    "            self.postnet: _Postnet = postnet\n",
    "        self.version = '0.01'\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        tokens: Tensor,\n",
    "        token_lengths: Tensor,\n",
    "        mel_specgram: Tensor,\n",
    "        mel_specgram_lengths: Tensor,\n",
    "        speaker_emb: Optional[Tensor]=None,\n",
    "        alpha: int = 0,\n",
    "    ):\n",
    "        embedded_inputs = self.embedding(tokens).transpose(1, 2) \n",
    "\n",
    "        mel_specgram, gate_outputs, alignments = self.decoder(\n",
    "            embedded_inputs, mel_specgram, memory_lengths=token_lengths,\n",
    "        )\n",
    "\n",
    "        mel_specgram_postnet = self.postnet(mel_specgram)\n",
    "        mel_specgram_postnet = mel_specgram + mel_specgram_postnet\n",
    "\n",
    "        if self.mask_padding:\n",
    "            mask = _get_mask_from_lengths(mel_specgram_lengths)\n",
    "            mask = mask.expand(self.n_mels, mask.size(0), mask.size(1))\n",
    "            mask = mask.permute(1, 0, 2)\n",
    "\n",
    "            mel_specgram.masked_fill_(mask, 0.0)\n",
    "            mel_specgram_postnet.masked_fill_(mask, 0.0)\n",
    "            gate_outputs.masked_fill_(mask[:, 0, :], 1e3)\n",
    "\n",
    "        return mel_specgram, mel_specgram_postnet, gate_outputs, alignments\n",
    "\n",
    "    @torch.jit.export\n",
    "    def infer(self, tokens: Tensor, lengths: Optional[Tensor] = None, speaker_emb: Optional[Tensor]=None) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        n_batch, max_length = tokens.shape\n",
    "        if lengths is None:\n",
    "            lengths = torch.tensor([max_length]).expand(n_batch).to(tokens.device, tokens.dtype)\n",
    "\n",
    "        assert lengths is not None  # For TorchScript compiler\n",
    "\n",
    "        embedded_inputs = self.embedding(tokens).transpose(1, 2)\n",
    "        encoder_outputs = self.encoder(embedded_inputs, lengths)\n",
    "        \n",
    "        mel_specgram, mel_specgram_lengths, _, alignments = self.decoder.infer(encoder_outputs, lengths)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_specgram)\n",
    "        mel_outputs_postnet = mel_specgram + mel_outputs_postnet\n",
    "\n",
    "        alignments = alignments.unfold(1, n_batch, n_batch).transpose(0, 2)\n",
    "\n",
    "        return mel_outputs_postnet, mel_specgram_lengths, alignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3322949f56cb4db99427e05ed2d4a87f0497ffa3e41dd81b99d577253bd3be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
