{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_initial_table, get_final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语音数据集预处理\n",
    "\n",
    "- 将连续的多音节重叠到一起，划分单个汉字的时间\n",
    "- 延长发音需要标注出来，确定为延长，方便之后生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_table = get_initial_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(x): \n",
    "    for s in x:\n",
    "        print(len(s), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcriptions(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        if (lines[-1]==''):\n",
    "            lines = lines[:-1]\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/opencpop/segments/'\n",
    "lines = get_transcriptions(path+'train.txt')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(id, path, sr = 16000):\n",
    "    wav_path = path+'wavs/'+str(id)+'.wav'\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    if sample_rate != sr:\n",
    "        waveform = torchaudio.functional.resample(waveform[0].unsqueeze(0), sample_rate, sr)\n",
    "    return waveform\n",
    "\n",
    "def parser_line(line):\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = line.split('|')\n",
    "    phoneme = phoneme.split(' ')\n",
    "    note = note.split(' ')\n",
    "    note_duration = [float(i) for i in note_duration.split(' ')]\n",
    "    phoneme_duration = [float(i) for i in phoneme_duration.split(' ')]\n",
    "    slur_note = [int(i) for i in slur_note.split(' ')]\n",
    "    assert len(phoneme) == len(note_duration) and len(phoneme_duration) == len(slur_note) and len(slur_note) == len(phoneme)\n",
    "    return id, text, phoneme, note, note_duration, phoneme_duration, slur_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看下一共用到了多少元音辅音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'到现在'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_set = set()\n",
    "note_set = set()\n",
    "min_note_duration = 100\n",
    "max_note_duration = -1\n",
    "note_durations = []\n",
    "for line in lines:\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(line)\n",
    "    phoneme_set.update(set(phoneme))\n",
    "    note_set.update(set(note))\n",
    "    note_durations.extend(note_duration)\n",
    "    if max(note_duration) > max_note_duration:\n",
    "        max_note_duration = max(note_duration)\n",
    "        max_note_id = text\n",
    "    if min(note_duration) < min_note_duration:\n",
    "        min_note_duration = min(note_duration)\n",
    "\n",
    "max_note_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(note_durations, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 {'uai', 'ian', 'm', 'q', 'ong', 'ao', 'b', 'e', 'ie', 'r', 'a', 'iong', 'ua', 'AP', 'ou', 'iang', 'ia', 'd', 'iu', 'u', 'iao', 'p', 'uang', 't', 'ai', 'van', 'in', 'ei', 'k', 'ang', 'ch', 'v', 's', 'an', 'ui', 'h', 'sh', 'eng', 'uo', 'w', 'un', 'j', 'g', 'n', 'i', 'ing', 'y', 'SP', 'uan', 'zh', 'x', 'c', 'er', 'o', 'z', 'vn', 've', 'f', 'en', 'l'}\n",
      "35 {'B4', 'C4', 'F3', 'F5', 'E3', 'E4', 'G3', 'A5', 'G#4/Ab4', 'A4', 'A#3/Bb3', 'B3', 'F#4/Gb4', 'D4', 'D#5/Eb5', 'F#3/Gb3', 'C5', 'E5', 'C#5/Db5', 'A#4/Bb4', 'D#3/Eb3', 'C#3/Db3', 'F#5/Gb5', 'D3', 'D2', 'F4', 'G4', 'C#2/Db2', 'C3', 'D5', 'rest', 'C#4/Db4', 'A3', 'D#4/Eb4', 'G#3/Ab3'}\n",
      "6.35453 0.0071\n"
     ]
    }
   ],
   "source": [
    "print_all([phoneme_set,note_set])\n",
    "print(max_note_duration, min_note_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'-', 'iou', 'uei', 'uen', 'ueng', '|', 'ê'}, {'AP', 'SP', 'iu', 'ui', 'un'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import get_phoneme_labels\n",
    "phoneme_labels = get_phoneme_labels()\n",
    "set(phoneme_labels) - phoneme_set, phoneme_set - set(phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transposed_phoneme_labels():\n",
    "    phoneme_list = get_initial_table() + get_final_table()\n",
    "    for x in ['iou', 'uei', 'uen', 'ueng', 'ê']:\n",
    "        phoneme_list.remove(x)\n",
    "    phoneme_list += ['iu', 'ui', 'un', 'AP', 'SP']\n",
    "    return ['-', '|']+phoneme_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '|', 'b', 'p', 'm', 'f', 'd', 't', 'n', 'l', 'g', 'k', 'h', 'j', 'q', 'x', 'zh', 'ch', 'sh', 'r', 'z', 'c', 's', 'y', 'w', 'i', 'u', 'v', 'a', 'ia', 'ua', 'o', 'uo', 'e', 'ie', 've', 'ai', 'uai', 'ei', 'ao', 'iao', 'ou', 'an', 'ian', 'uan', 'van', 'en', 'in', 'vn', 'ang', 'iang', 'uang', 'eng', 'ing', 'ong', 'iong', 'er', 'iu', 'ui', 'un', 'AP', 'SP']\n"
     ]
    }
   ],
   "source": [
    "phoneme_labels = get_transposed_phoneme_labels()\n",
    "print(phoneme_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打一个示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2001000006|漂浮在一片无奈|p iao f u z ai ai ai AP SP y i i p ian ian ian w u n ai SP AP|E4 E4 F#4/Gb4 F#4/Gb4 G#4/Ab4 G#4/Ab4 A4 G#4/Ab4 rest rest E4 E4 F#4/Gb4 G#4/Ab4 G#4/Ab4 A4 G#4/Ab4 E4 E4 F#4/Gb4 F#4/Gb4 rest rest|0.185230 0.185230 0.177410 0.177410 0.193930 0.193930 0.259670 0.299340 0.215550 0.031770 0.197520 0.197520 0.165450 0.184760 0.184760 0.212290 0.246960 0.440370 0.440370 1.524950 1.524950 0.855830 0.559100|0.06011 0.12512 0.07517 0.10224 0.08603 0.1079 0.25967 0.29934 0.21555 0.03177 0.05175 0.14577 0.16545 0.0748 0.10996 0.21229 0.24696 0.09617 0.3442 0.1437 1.38125 0.85583 0.5591|0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = lines[5]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2001000006\n",
      "7 漂浮在一片无奈\n",
      "23 ['p', 'iao', 'f', 'u', 'z', 'ai', 'ai', 'ai', 'AP', 'SP', 'y', 'i', 'i', 'p', 'ian', 'ian', 'ian', 'w', 'u', 'n', 'ai', 'SP', 'AP']\n",
      "23 ['E4', 'E4', 'F#4/Gb4', 'F#4/Gb4', 'G#4/Ab4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'rest', 'rest', 'E4', 'E4', 'F#4/Gb4', 'G#4/Ab4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'E4', 'E4', 'F#4/Gb4', 'F#4/Gb4', 'rest', 'rest']\n",
      "23 [0.18523, 0.18523, 0.17741, 0.17741, 0.19393, 0.19393, 0.25967, 0.29934, 0.21555, 0.03177, 0.19752, 0.19752, 0.16545, 0.18476, 0.18476, 0.21229, 0.24696, 0.44037, 0.44037, 1.52495, 1.52495, 0.85583, 0.5591]\n",
      "23 [0.06011, 0.12512, 0.07517, 0.10224, 0.08603, 0.1079, 0.25967, 0.29934, 0.21555, 0.03177, 0.05175, 0.14577, 0.16545, 0.0748, 0.10996, 0.21229, 0.24696, 0.09617, 0.3442, 0.1437, 1.38125, 0.85583, 0.5591]\n",
      "23 [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(line)\n",
    "print_all([id, text, phoneme, note, note_duration, phoneme_duration, slur_note])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音频文件读取测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 92003])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform = get_audio(id, path)\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "汉字元音辅音组合为单个汉字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'u', 'v', 'a', 'ia', 'ua', 'o', 'uo', 'e', 'ie', 've', 'ai', 'uai', 'ei', 'uei', 'ao', 'iao', 'ou', 'iou', 'an', 'ian', 'uan', 'van', 'en', 'in', 'uen', 'vn', 'ang', 'iang', 'uang', 'eng', 'ing', 'ueng', 'ong', 'iong', 'er', 'ê']\n"
     ]
    }
   ],
   "source": [
    "print(get_final_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_note(text, phoneme, note, note_duration, slur_note):\n",
    "    # 1. check whether the phoneme is in finals\n",
    "    INITIALS = get_initial_table()\n",
    "    FINALS = get_final_table()\n",
    "    # is_final = [1 if p in FINALS else 0 for p in phoneme]\n",
    "    phoneme = phoneme.copy()\n",
    "    note = note.copy()\n",
    "    note_duration = note_duration.copy()\n",
    "    slur_note = slur_note.copy()\n",
    "    j = -1\n",
    "    text+='////////////////////'\n",
    "    text_with_p = phoneme.copy()\n",
    "    used_flag = False\n",
    "    for i in range(len(text_with_p)):\n",
    "        if text_with_p[i] in ['AP', 'SP']:\n",
    "            continue\n",
    "        if j==-1 or phoneme[i] in INITIALS or (phoneme[i-1] not in INITIALS and phoneme[i] != phoneme[i-1]):\n",
    "            j+=1\n",
    "            used_flag = False\n",
    "        text_with_p[i] = text[j] if used_flag == False else '~'\n",
    "        used_flag = True\n",
    "    for i in range(len(phoneme)-1, 0, -1):\n",
    "        if (note_duration[i] == note_duration[i-1] and phoneme[i-1] in INITIALS):\n",
    "            del note_duration[i]\n",
    "            del note[i]\n",
    "            phoneme[i-1]=[phoneme[i-1],phoneme[i]]\n",
    "            del phoneme[i]\n",
    "            del text_with_p[i]\n",
    "            del slur_note[i]\n",
    "        elif phoneme[i] in FINALS or phoneme[i] in ['AP', 'SP']:\n",
    "            phoneme[i] = [phoneme[i], '-']\n",
    "    return text_with_p, phoneme, note, note_duration, slur_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['漂', '浮', '在', '~', '~', 'AP', 'SP', '一', '~', '片', '~', '~', '无', '奈', 'SP', 'AP']\n",
      "16 [['p', 'iao'], ['f', 'u'], ['z', 'ai'], ['ai', '-'], ['ai', '-'], ['AP', '-'], ['SP', '-'], ['y', 'i'], ['i', '-'], ['p', 'ian'], ['ian', '-'], ['ian', '-'], ['w', 'u'], ['n', 'ai'], ['SP', '-'], ['AP', '-']]\n",
      "16 ['E4', 'F#4/Gb4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'rest', 'rest', 'E4', 'F#4/Gb4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'E4', 'F#4/Gb4', 'rest', 'rest']\n",
      "16 [0.18523, 0.17741, 0.19393, 0.25967, 0.29934, 0.21555, 0.03177, 0.19752, 0.16545, 0.18476, 0.21229, 0.24696, 0.44037, 1.52495, 0.85583, 0.5591]\n",
      "16 [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_all(merge_note(text, phoneme, note, note_duration, slur_note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SpeechDataset\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpencpopDataset(SpeechDataset):\n",
    "\n",
    "    def __init__(self, data_path, sample_rate=16000, transform=None):\n",
    "        super().__init__(data_path, sample_rate, transform)\n",
    "        transcript_file = data_path+'transcriptions.txt'\n",
    "        self.transcript = self.gen_transcript(transcript_file)\n",
    "        self.dataset_file_num = len(self.transcript)\n",
    "        self.threshold = 120000 # to avoid GPU memory used out\n",
    "        self.batch_size = 80 # to avoid GPU memory used out\n",
    "        self.split_ratio = [1000, 3]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_file_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if idx >= self.dataset_file_num:\n",
    "            return {'audio': None, 'text': None}\n",
    "        line = self.transcript[idx]\n",
    "        id, text, phoneme, note, note_duration, phoneme_duration, slur_note = self.parser_line(line)\n",
    "        waveform = self.get_audio(id)\n",
    "        # text_with_p, phoneme, note, note_duration = merge_note(text, phoneme, note, note_duration)\n",
    "        sample = {'audio': waveform, 'text': line}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample, self.sample_rate)\n",
    "        return sample\n",
    "\n",
    "    def get_audio(self, id):\n",
    "        wav_path = self.data_path+'wavs/'+str(id)+'.wav'\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        if sample_rate != self.sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform[0].unsqueeze(0), sample_rate, self.sample_rate)\n",
    "        return waveform\n",
    "\n",
    "    def parser_line(self, line):\n",
    "        id, text, phoneme, note, note_duration, phoneme_duration, slur_note = line.split('|')\n",
    "        phoneme = phoneme.split(' ')\n",
    "        note = note.split(' ')\n",
    "        note_duration = [float(i) for i in note_duration.split(' ')]\n",
    "        phoneme_duration = [float(i) for i in phoneme_duration.split(' ')]\n",
    "        slur_note = [int(i) for i in slur_note.split(' ')]\n",
    "        assert len(phoneme) == len(note_duration) and len(phoneme_duration) == len(slur_note) and len(slur_note) == len(phoneme)\n",
    "        return id, text, phoneme, note, note_duration, phoneme_duration, slur_note\n",
    "\n",
    "    def gen_transcript(self, transcript_file):\n",
    "        with open(transcript_file) as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            if (lines[-1]==''):\n",
    "                lines = lines[:-1]\n",
    "            return lines\n",
    "\n",
    "    def split(self, split_ratio=None, seed=42):\n",
    "        audio_dataset = self\n",
    "        size = len(audio_dataset)\n",
    "        my_split_ratio = self.split_ratio if split_ratio is None else split_ratio\n",
    "        lengths = [(i*size)//sum(my_split_ratio) for i in my_split_ratio]\n",
    "        lengths[-1] = size - sum(lengths[:-1])\n",
    "        split_dataset = random_split(audio_dataset, lengths, generator=torch.Generator().manual_seed(seed))\n",
    "        return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataset_transform(sample, sample_rate=None):\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(sample['text'])\n",
    "    text_with_p, phoneme, note, note_duration, slur_note = merge_note(text, phoneme, note, note_duration, slur_note)\n",
    "    sample['chinese'] = text_with_p\n",
    "    sample['phoneme'] = phoneme\n",
    "    sample['note'] = note\n",
    "    sample['duration'] = note_duration\n",
    "    sample['slur'] = slur_note\n",
    "    return sample\n",
    "\n",
    "dataset = OpencpopDataset('/scratch/bh2283/data/opencpop/segments/', transform=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([[-0.0005, -0.0008, -0.0008,  ...,  0.0003,  0.0003,  0.0003]])\n",
      "514 2001000002|如何瞬间冻结时间|r u h e sh un j ian AP SP d ong j ie sh i j ian SP|B3 B3 B3 B3 B3 B3 G#4/Ab4 G#4/Ab4 rest rest B3 B3 B3 B3 B3 B3 F#4/Gb4 F#4/Gb4 rest|0.294760 0.294760 0.283550 0.283550 0.795250 0.795250 0.992200 0.992200 0.297130 0.104830 0.311040 0.311040 0.214620 0.214620 0.782750 0.782750 1.519540 1.519540 1.179120|0.06588 0.22888 0.11684 0.16671 0.18746 0.60779 0.11194 0.88026 0.29713 0.10483 0.03166 0.27938 0.05057 0.16405 0.21149 0.57126 0.13926 1.38028 1.17912|0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11 ['如', '何', '瞬', '间', 'AP', 'SP', '冻', '结', '时', '间', 'SP']\n",
      "11 [['r', 'u'], ['h', 'e'], ['sh', 'un'], ['j', 'ian'], ['AP', '-'], ['SP', '-'], ['d', 'ong'], ['j', 'ie'], ['sh', 'i'], ['j', 'ian'], ['SP', '-']]\n",
      "11 ['B3', 'B3', 'B3', 'G#4/Ab4', 'rest', 'rest', 'B3', 'B3', 'B3', 'F#4/Gb4', 'rest']\n",
      "11 [0.29476, 0.28355, 0.79525, 0.9922, 0.29713, 0.10483, 0.31104, 0.21462, 0.78275, 1.51954, 1.17912]\n",
      "11 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_all(dataset[1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3744, 12)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = dataset.split()\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单个字测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(waveform):\n",
    "    torchaudio.save('./audio-temp.wav', waveform.unsqueeze(0), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 99361])\n",
      "[0.39009, 0.76237, 1.1684299999999999, 1.4763199999999999, 2.06518, 2.5804, 3.4135400000000002, 5.350750000000001, 5.77657, 6.210050000000001]\n",
      "['一', '起', '看', '晚', '霞', '~', '满', '天', 'SP', 'AP'] AP 0.43348 AP-\n",
      "0.39\n"
     ]
    }
   ],
   "source": [
    "def test_one_char(data, idx, sample_rate = 16000):\n",
    "    assert idx < len(data['chinese'])\n",
    "    chinese = data['chinese'][idx]\n",
    "    time = data['duration'][idx]\n",
    "    duration = data['duration']\n",
    "    for i in range(1, len(duration)):\n",
    "        duration[i] += duration[i-1]\n",
    "    start = 0 if idx == 0 else int(duration[idx-1]*sample_rate)\n",
    "    end = int(duration[idx]*sample_rate)\n",
    "    print(data['audio'].shape)\n",
    "    waveform = data['audio'][0, start: end]\n",
    "    print(duration)\n",
    "    print(data['chinese'], chinese, time, ''.join(data['phoneme'][idx]))\n",
    "    play(waveform)\n",
    "    print('%.2f' % duration[0])\n",
    "\n",
    "test_one_char(train_set[5], 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "靠耳朵听，发现大部分的标注是准确的，也有小部分划分有点出入。\n",
    "文本注音也有些问题，但是问题不大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "这儿我们制作一个单个字的dataloader，包含拼音、音调、时常（量化后），延音。\n",
    "\n",
    "之后使用lookup emb制作decoder的输入emb。这儿注意可以使用前一个字后一个字来辅助生成更好的声音。如果这样做，注意前一个字，本字，后一个字都需要使用不同的lookup table。\n",
    "\n",
    "先做一个naive版本，前后一个字不考虑。即使如此，我们的dataloader任然需要提供所有信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['audio', 'text', 'chinese', 'phoneme', 'note', 'duration', 'slur'])\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLoaderGenerator:\n",
    "    def __init__(self, \n",
    "        labels,\n",
    "        num_workers=0,\n",
    "        sample_rate = 16000,\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ) -> None:\n",
    "        self.phoneme_labels, self.note_labels, self.duration_labels, self.slur_labels = labels\n",
    "        self.phoneme_look_up = {s: i for i, s in enumerate(self.phoneme_labels)}\n",
    "        self.note_look_up = {s: i for i, s in enumerate(self.note_labels)}\n",
    "        self.duration_look_up = {s: i for i, s in enumerate(self.duration_labels)}\n",
    "        self.slur_look_up = {s: i for i, s in enumerate(self.slur_labels)}\n",
    "        self.device = device\n",
    "        self.num_workers = num_workers\n",
    "        self.sample_rate = sample_rate\n",
    "        self.version = '0.01'\n",
    "\n",
    "    def label2id(self, look_up, str):\n",
    "        if isinstance(str[0], list):\n",
    "            return [[look_up[i] for i in sub] for sub in str]\n",
    "        return [look_up[i] for i in str]\n",
    "\n",
    "    def id2label(self, labels, idcs):\n",
    "        return ''.join([labels[i] for i in idcs])\n",
    "\n",
    "    def collate_wrapper(self, batch:list): # RAW\n",
    "        bs = len(batch)\n",
    "        sample_rate = self.sample_rate\n",
    "        audio, audio_len, audio_duration, audio_duration_quant, chinese, phoneme,\\\n",
    "            phoneme_pre, phoneme_post, note, note_pre, note_post, slur = [], [], [], [], [], [], [], [], [], [], [], []\n",
    "        for data in batch:\n",
    "            audio_f = data['audio']\n",
    "            chinese_f = data['chinese']\n",
    "            phoneme_f = data['phoneme']\n",
    "            note_f = data['note']\n",
    "            duration_f = data['duration']\n",
    "            duration_cum = duration_f.copy()\n",
    "            for i in range(1, len(duration_cum)):\n",
    "                duration_cum[i] += duration_cum[i-1]\n",
    "            slur_f = data['slur']\n",
    "            for i in range(len(chinese_f)):\n",
    "                start = 0 if i == 0 else int(duration_cum[i-1]*sample_rate)\n",
    "                end = int(duration_cum[i]*sample_rate)\n",
    "                wave_chunk = audio_f[0, start: end]\n",
    "                audio.append(wave_chunk)\n",
    "                audio_len.append(len(wave_chunk))\n",
    "                audio_duration.append(duration_f[i])\n",
    "                audio_duration_quant.append('%.2f' % duration_f[i])\n",
    "                chinese.append(chinese_f[i])\n",
    "                phoneme.append(phoneme_f[i])\n",
    "                phoneme_pre.append(phoneme_f[i-1]if i>0 else ['SP'])\n",
    "                phoneme_post.append(phoneme_f[i+1]if i+1<len(phoneme_f) else ['SP'])\n",
    "                note.append(note_f[i])\n",
    "                note_pre.append(note_f[i-1]if i>0 else 'rest')\n",
    "                note_post.append(note_f[i+1]if i+1<len(note_f) else 'rest')\n",
    "                slur.append(slur_f[i])\n",
    "        \n",
    "        return {\n",
    "            'audio': audio,  # 单个字的raw音频\n",
    "            'audio_len': audio_len, # 该音频数据长度\n",
    "            'audio_duration': audio_duration, # 真实音屏时间长度\n",
    "            'audio_duration_quant': audio_duration_quant, # 量化后音屏时间长度\n",
    "            'chinese': chinese, # 该音频汉字\n",
    "            'phoneme': self.label2id(self.phoneme_look_up, phoneme), # 拼音\n",
    "            'phoneme_pre': self.label2id(self.phoneme_look_up, phoneme_pre), # 前一个汉字的拼音\n",
    "            'phoneme_post': self.label2id(self.phoneme_look_up, phoneme_post), # 后一个汉字的拼音\n",
    "            'note': self.label2id(self.note_look_up, note), # 音调音符\n",
    "            'note_pre': self.label2id(self.note_look_up, note_pre),\n",
    "            'note_post': self.label2id(self.note_look_up, note_post),\n",
    "            'slur': self.label2id(self.slur_look_up, slur), # 是否为延长音\n",
    "            }\n",
    "\n",
    "    def dataloader(self, audioDataset, batch_size, shuffle=True):\n",
    "        # k_size is the kernel size for the encoder, for data augmentation\n",
    "        self.threshold = audioDataset.dataset.threshold\n",
    "        return DataLoader(audioDataset, batch_size,\n",
    "                            shuffle, num_workers=self.num_workers, collate_fn=self.collate_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_pitch_labels\n",
    "note_labels = get_pitch_labels()\n",
    "slur_labels = [0, 1]\n",
    "# 0-1 分辨率0.01，1-2 分辨率0.05，2-7 分辨率0.2\n",
    "duration_labels = [i for i in range(700)] # max_note_duration is 6.x s, so we set max is 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 3744 test_set: 12\n",
      "['你', '就', '在', '对', '岸', 'SP', '等', '我', '勇', '敢', '你', '还', '是', '我', '的', 'AP', '我', '的', '我', 'SP', '的', 'SP', 'AP', 'SP', '清', '清', '楚', '楚', '地', '说', '你', '爱', '我', 'AP']\n",
      "[[8, 25], [13, 57], [20, 36], [6, 58], [42, 0], [61, 0], [6, 52], [24, 31], [23, 54], [10, 42], [8, 25], [12, 36], [18, 25], [24, 31], [6, 33], [60, 0], [24, 31], [6, 33], [24, 31], [61, 0], [6, 33], [61, 0], [60, 0], [61, 0], [14, 53], [14, 53], [17, 26], [17, 26], [6, 25], [18, 32], [8, 25], [36, 0], [24, 31], [60, 0]]\n"
     ]
    }
   ],
   "source": [
    "labels = (\n",
    "    phoneme_labels,\n",
    "    note_labels,\n",
    "    duration_labels,\n",
    "    slur_labels\n",
    ")\n",
    "loaderGenerator = MusicLoaderGenerator(labels)\n",
    "train_loader = loaderGenerator.dataloader(train_set, batch_size=2)\n",
    "print('train_set:', len(train_set), 'test_set:',len(test_set))\n",
    "steps = 1\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    if steps <= 0:\n",
    "        break\n",
    "    print(sample_batched['chinese'])\n",
    "    print(sample_batched['phoneme'])\n",
    "    steps -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3322949f56cb4db99427e05ed2d4a87f0497ffa3e41dd81b99d577253bd3be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
