{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_initial_table, get_final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语音数据集预处理\n",
    "\n",
    "- 将连续的多音节重叠到一起，划分单个汉字的时间\n",
    "- 延长发音需要标注出来，确定为延长，方便之后生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_table = get_initial_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(x): \n",
    "    for s in x:\n",
    "        if len(s) == 1 and isinstance(s, torch.Tensor):\n",
    "            print(s.shape)\n",
    "            continue\n",
    "        print(len(s), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcriptions(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        if (lines[-1]==''):\n",
    "            lines = lines[:-1]\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/opencpop/segments/'\n",
    "lines = get_transcriptions(path+'train.txt')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(id, path, sr = sample_rate):\n",
    "    wav_path = path+'wavs/'+str(id)+'.wav'\n",
    "    waveform, sample_rate = torchaudio.load(wav_path, normalize=True)\n",
    "    if sample_rate != sr:\n",
    "        waveform = torchaudio.functional.resample(waveform[0].unsqueeze(0), sample_rate, sr)\n",
    "    return waveform\n",
    "\n",
    "def parser_line(line):\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = line.split('|')\n",
    "    phoneme = phoneme.split(' ')\n",
    "    note = note.split(' ')\n",
    "    note_duration = [float(i) for i in note_duration.split(' ')]\n",
    "    phoneme_duration = [float(i) for i in phoneme_duration.split(' ')]\n",
    "    slur_note = [int(i) for i in slur_note.split(' ')]\n",
    "    assert len(phoneme) == len(note_duration) and len(phoneme_duration) == len(slur_note) and len(slur_note) == len(phoneme)\n",
    "    return id, text, phoneme, note, note_duration, phoneme_duration, slur_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看下一共用到了多少元音辅音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'到现在'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_set = set()\n",
    "note_set = set()\n",
    "min_note_duration = 100\n",
    "max_note_duration = -1\n",
    "note_durations = []\n",
    "for line in lines:\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(line)\n",
    "    phoneme_set.update(set(phoneme))\n",
    "    note_set.update(set(note))\n",
    "    note_durations.extend(note_duration)\n",
    "    if max(note_duration) > max_note_duration:\n",
    "        max_note_duration = max(note_duration)\n",
    "        max_note_id = text\n",
    "    if min(note_duration) < min_note_duration:\n",
    "        min_note_duration = min(note_duration)\n",
    "\n",
    "max_note_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要依赖下图进行时间分辨率量化embedding。\n",
    "\n",
    "在0-1之间，密集，所以需要精细的分辨率，比如0.01，之后可以降低分辨率，比如改为0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(note_durations, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 {'ei', 'van', 'uo', 'ia', 'sh', 'ong', 'q', 'o', 'SP', 'ian', 'w', 'an', 'g', 'eng', 'er', 'vn', 'iong', 'i', 'c', 'd', 'uai', 'ui', 't', 'e', 'l', 'in', 'f', 'AP', 'zh', 'j', 'iang', 's', 'iu', 'ua', 'ai', 'uan', 'ch', 'en', 'z', 'ing', 'm', 'u', 'a', 'ie', 'p', 'r', 'n', 'ao', 've', 'x', 'k', 'b', 'ang', 'y', 'ou', 'iao', 'uang', 'un', 'v', 'h'}\n",
      "35 {'A#3/Bb3', 'F3', 'D#5/Eb5', 'D4', 'G#4/Ab4', 'B3', 'F4', 'C5', 'F#4/Gb4', 'C4', 'B4', 'A3', 'C#5/Db5', 'A#4/Bb4', 'F#3/Gb3', 'D#4/Eb4', 'A5', 'D3', 'D5', 'F#5/Gb5', 'G#3/Ab3', 'D#3/Eb3', 'E4', 'C#3/Db3', 'C3', 'F5', 'G3', 'C#4/Db4', 'E3', 'G4', 'D2', 'C#2/Db2', 'rest', 'A4', 'E5'}\n",
      "6.35453 0.0071\n"
     ]
    }
   ],
   "source": [
    "print_all([phoneme_set,note_set])\n",
    "print(max_note_duration, min_note_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'-', 'iou', 'uei', 'uen', 'ueng', '|', 'ê'}, {'AP', 'SP', 'iu', 'ui', 'un'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import get_phoneme_labels\n",
    "phoneme_labels = get_phoneme_labels()\n",
    "set(phoneme_labels) - phoneme_set, phoneme_set - set(phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transposed_phoneme_labels():\n",
    "    phoneme_list = get_initial_table() + get_final_table()\n",
    "    for x in ['iou', 'uei', 'uen', 'ueng', 'ê']:\n",
    "        phoneme_list.remove(x)\n",
    "    phoneme_list += ['iu', 'ui', 'un', 'AP', 'SP']\n",
    "    return ['-', '|']+phoneme_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '|', 'b', 'p', 'm', 'f', 'd', 't', 'n', 'l', 'g', 'k', 'h', 'j', 'q', 'x', 'zh', 'ch', 'sh', 'r', 'z', 'c', 's', 'y', 'w', 'i', 'u', 'v', 'a', 'ia', 'ua', 'o', 'uo', 'e', 'ie', 've', 'ai', 'uai', 'ei', 'ao', 'iao', 'ou', 'an', 'ian', 'uan', 'van', 'en', 'in', 'vn', 'ang', 'iang', 'uang', 'eng', 'ing', 'ong', 'iong', 'er', 'iu', 'ui', 'un', 'AP', 'SP']\n"
     ]
    }
   ],
   "source": [
    "phoneme_labels = get_transposed_phoneme_labels()\n",
    "print(phoneme_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打一个示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2001000006|漂浮在一片无奈|p iao f u z ai ai ai AP SP y i i p ian ian ian w u n ai SP AP|E4 E4 F#4/Gb4 F#4/Gb4 G#4/Ab4 G#4/Ab4 A4 G#4/Ab4 rest rest E4 E4 F#4/Gb4 G#4/Ab4 G#4/Ab4 A4 G#4/Ab4 E4 E4 F#4/Gb4 F#4/Gb4 rest rest|0.185230 0.185230 0.177410 0.177410 0.193930 0.193930 0.259670 0.299340 0.215550 0.031770 0.197520 0.197520 0.165450 0.184760 0.184760 0.212290 0.246960 0.440370 0.440370 1.524950 1.524950 0.855830 0.559100|0.06011 0.12512 0.07517 0.10224 0.08603 0.1079 0.25967 0.29934 0.21555 0.03177 0.05175 0.14577 0.16545 0.0748 0.10996 0.21229 0.24696 0.09617 0.3442 0.1437 1.38125 0.85583 0.5591|0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = lines[5]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2001000006\n",
      "7 漂浮在一片无奈\n",
      "23 ['p', 'iao', 'f', 'u', 'z', 'ai', 'ai', 'ai', 'AP', 'SP', 'y', 'i', 'i', 'p', 'ian', 'ian', 'ian', 'w', 'u', 'n', 'ai', 'SP', 'AP']\n",
      "23 ['E4', 'E4', 'F#4/Gb4', 'F#4/Gb4', 'G#4/Ab4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'rest', 'rest', 'E4', 'E4', 'F#4/Gb4', 'G#4/Ab4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'E4', 'E4', 'F#4/Gb4', 'F#4/Gb4', 'rest', 'rest']\n",
      "23 [0.18523, 0.18523, 0.17741, 0.17741, 0.19393, 0.19393, 0.25967, 0.29934, 0.21555, 0.03177, 0.19752, 0.19752, 0.16545, 0.18476, 0.18476, 0.21229, 0.24696, 0.44037, 0.44037, 1.52495, 1.52495, 0.85583, 0.5591]\n",
      "23 [0.06011, 0.12512, 0.07517, 0.10224, 0.08603, 0.1079, 0.25967, 0.29934, 0.21555, 0.03177, 0.05175, 0.14577, 0.16545, 0.0748, 0.10996, 0.21229, 0.24696, 0.09617, 0.3442, 0.1437, 1.38125, 0.85583, 0.5591]\n",
      "23 [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(line)\n",
    "print_all([id, text, phoneme, note, note_duration, phoneme_duration, slur_note])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音频文件读取测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 126791])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform = get_audio(id, path)\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "汉字元音辅音组合为单个汉字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'u', 'v', 'a', 'ia', 'ua', 'o', 'uo', 'e', 'ie', 've', 'ai', 'uai', 'ei', 'uei', 'ao', 'iao', 'ou', 'iou', 'an', 'ian', 'uan', 'van', 'en', 'in', 'uen', 'vn', 'ang', 'iang', 'uang', 'eng', 'ing', 'ueng', 'ong', 'iong', 'er', 'ê']\n"
     ]
    }
   ],
   "source": [
    "print(get_final_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_note(text, phoneme, note, note_duration, slur_note):\n",
    "    # 1. check whether the phoneme is in finals\n",
    "    INITIALS = get_initial_table()\n",
    "    FINALS = get_final_table()\n",
    "    # is_final = [1 if p in FINALS else 0 for p in phoneme]\n",
    "    phoneme = phoneme.copy()\n",
    "    note = note.copy()\n",
    "    note_duration = note_duration.copy()\n",
    "    slur_note = slur_note.copy()\n",
    "    j = -1\n",
    "    text+='////////////////////'\n",
    "    text_with_p = phoneme.copy()\n",
    "    used_flag = False\n",
    "    for i in range(len(text_with_p)):\n",
    "        if text_with_p[i] in ['AP', 'SP']:\n",
    "            continue\n",
    "        if j==-1 or phoneme[i] in INITIALS or (phoneme[i-1] not in INITIALS and phoneme[i] != phoneme[i-1]):\n",
    "            j+=1\n",
    "            used_flag = False\n",
    "        text_with_p[i] = text[j] if used_flag == False else '~'\n",
    "        used_flag = True\n",
    "    for i in range(len(phoneme)-1, 0, -1):\n",
    "        if (note_duration[i] == note_duration[i-1] and phoneme[i-1] in INITIALS):\n",
    "            del note_duration[i]\n",
    "            del note[i]\n",
    "            phoneme[i-1]=[phoneme[i-1],phoneme[i]]\n",
    "            del phoneme[i]\n",
    "            del text_with_p[i]\n",
    "            del slur_note[i]\n",
    "        elif phoneme[i] in FINALS or phoneme[i] in ['AP', 'SP']:\n",
    "            phoneme[i] = [phoneme[i], '-']\n",
    "    return text_with_p, phoneme, note, note_duration, slur_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['漂', '浮', '在', '~', '~', 'AP', 'SP', '一', '~', '片', '~', '~', '无', '奈', 'SP', 'AP']\n",
      "16 [['p', 'iao'], ['f', 'u'], ['z', 'ai'], ['ai', '-'], ['ai', '-'], ['AP', '-'], ['SP', '-'], ['y', 'i'], ['i', '-'], ['p', 'ian'], ['ian', '-'], ['ian', '-'], ['w', 'u'], ['n', 'ai'], ['SP', '-'], ['AP', '-']]\n",
      "16 ['E4', 'F#4/Gb4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'rest', 'rest', 'E4', 'F#4/Gb4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'E4', 'F#4/Gb4', 'rest', 'rest']\n",
      "16 [0.18523, 0.17741, 0.19393, 0.25967, 0.29934, 0.21555, 0.03177, 0.19752, 0.16545, 0.18476, 0.21229, 0.24696, 0.44037, 1.52495, 0.85583, 0.5591]\n",
      "16 [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_all(merge_note(text, phoneme, note, note_duration, slur_note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SpeechDataset\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpencpopDataset(SpeechDataset):\n",
    "\n",
    "    def __init__(self, data_path, sample_rate=sample_rate, transform=None):\n",
    "        super().__init__(data_path, sample_rate, transform)\n",
    "        transcript_file = data_path+'transcriptions.txt'\n",
    "        self.transcript = self.gen_transcript(transcript_file)\n",
    "        self.dataset_file_num = len(self.transcript)\n",
    "        self.threshold = 120000 # to avoid GPU memory used out\n",
    "        self.batch_size = 80 # to avoid GPU memory used out\n",
    "        self.split_ratio = [1000, 3]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_file_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if idx >= self.dataset_file_num:\n",
    "            return {'audio': None, 'text': None}\n",
    "        line = self.transcript[idx]\n",
    "        id, text, phoneme, note, note_duration, phoneme_duration, slur_note = self.parser_line(line)\n",
    "        waveform = self.get_audio(id)\n",
    "        # text_with_p, phoneme, note, note_duration = merge_note(text, phoneme, note, note_duration)\n",
    "        sample = {'audio': waveform, 'text': line}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample, self.sample_rate)\n",
    "        return sample\n",
    "\n",
    "    def get_audio(self, id):\n",
    "        wav_path = self.data_path+'wavs/'+str(id)+'.wav'\n",
    "        waveform, sample_rate = torchaudio.load(wav_path, normalize=True)\n",
    "        if sample_rate != self.sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform[0].unsqueeze(0), sample_rate, self.sample_rate)\n",
    "        return waveform\n",
    "\n",
    "    def parser_line(self, line):\n",
    "        id, text, phoneme, note, note_duration, phoneme_duration, slur_note = line.split('|')\n",
    "        phoneme = phoneme.split(' ')\n",
    "        note = note.split(' ')\n",
    "        note_duration = [float(i) for i in note_duration.split(' ')]\n",
    "        phoneme_duration = [float(i) for i in phoneme_duration.split(' ')]\n",
    "        slur_note = [int(i) for i in slur_note.split(' ')]\n",
    "        assert len(phoneme) == len(note_duration) and len(phoneme_duration) == len(slur_note) and len(slur_note) == len(phoneme)\n",
    "        return id, text, phoneme, note, note_duration, phoneme_duration, slur_note\n",
    "\n",
    "    def gen_transcript(self, transcript_file):\n",
    "        with open(transcript_file) as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            if (lines[-1]==''):\n",
    "                lines = lines[:-1]\n",
    "            return lines\n",
    "\n",
    "    def split(self, split_ratio=None, seed=42):\n",
    "        audio_dataset = self\n",
    "        size = len(audio_dataset)\n",
    "        my_split_ratio = self.split_ratio if split_ratio is None else split_ratio\n",
    "        lengths = [(i*size)//sum(my_split_ratio) for i in my_split_ratio]\n",
    "        lengths[-1] = size - sum(lengths[:-1])\n",
    "        split_dataset = random_split(audio_dataset, lengths, generator=torch.Generator().manual_seed(seed))\n",
    "        return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_transform(sample, sample_rate=None):\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(sample['text'])\n",
    "    text_with_p, phoneme, note, note_duration, slur_note = merge_note(text, phoneme, note, note_duration, slur_note)\n",
    "    sample['chinese'] = text_with_p\n",
    "    sample['phoneme'] = phoneme\n",
    "    sample['note'] = note\n",
    "    sample['duration'] = note_duration\n",
    "    sample['slur'] = slur_note\n",
    "    return sample\n",
    "\n",
    "dataset = OpencpopDataset('/scratch/bh2283/data/opencpop/segments/', transform=dataset_transform, sample_rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 149384])\n",
      "514 2001000002|如何瞬间冻结时间|r u h e sh un j ian AP SP d ong j ie sh i j ian SP|B3 B3 B3 B3 B3 B3 G#4/Ab4 G#4/Ab4 rest rest B3 B3 B3 B3 B3 B3 F#4/Gb4 F#4/Gb4 rest|0.294760 0.294760 0.283550 0.283550 0.795250 0.795250 0.992200 0.992200 0.297130 0.104830 0.311040 0.311040 0.214620 0.214620 0.782750 0.782750 1.519540 1.519540 1.179120|0.06588 0.22888 0.11684 0.16671 0.18746 0.60779 0.11194 0.88026 0.29713 0.10483 0.03166 0.27938 0.05057 0.16405 0.21149 0.57126 0.13926 1.38028 1.17912|0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11 ['如', '何', '瞬', '间', 'AP', 'SP', '冻', '结', '时', '间', 'SP']\n",
      "11 [['r', 'u'], ['h', 'e'], ['sh', 'un'], ['j', 'ian'], ['AP', '-'], ['SP', '-'], ['d', 'ong'], ['j', 'ie'], ['sh', 'i'], ['j', 'ian'], ['SP', '-']]\n",
      "11 ['B3', 'B3', 'B3', 'G#4/Ab4', 'rest', 'rest', 'B3', 'B3', 'B3', 'F#4/Gb4', 'rest']\n",
      "11 [0.29476, 0.28355, 0.79525, 0.9922, 0.29713, 0.10483, 0.31104, 0.21462, 0.78275, 1.51954, 1.17912]\n",
      "11 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_all(dataset[1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3744, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = dataset.split()\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单个字测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\\\n",
    "            n_fft=1024,power=1,hop_length=256,win_length=1024, n_mels=80, \\\n",
    "                f_min=0.0, f_max=8000.0, mel_scale=\"slaney\", norm=\"slaney\")\n",
    "                \n",
    "def play(waveform):\n",
    "    torchaudio.save('./audio-temp.wav', waveform.unsqueeze(0), 22050)\n",
    "    mel = mel_transform(waveform)\n",
    "    print('mel', mel.shape)\n",
    "    plt.imshow(mel.detach().numpy(), interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 136932])\n",
      "[0.39009, 0.76237, 1.1684299999999999, 1.4763199999999999, 2.06518, 2.5804, 3.4135400000000002, 5.350750000000001, 5.77657, 6.210050000000001]\n",
      "['一', '起', '看', '晚', '霞', '~', '满', '天', 'SP', 'AP'] 晚 0.30789 wan\n",
      "mel torch.Size([80, 20])\n",
      "0.39\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_one_char(data, idx, sample_rate = 16000):\n",
    "    assert idx < len(data['chinese'])\n",
    "    chinese = data['chinese'][idx]\n",
    "    time = data['duration'][idx]\n",
    "    duration = data['duration']\n",
    "    for i in range(1, len(duration)):\n",
    "        duration[i] += duration[i-1]\n",
    "    start = 0 if idx == 0 else int(duration[idx-1]*sample_rate)\n",
    "    end = int(duration[idx]*sample_rate)\n",
    "    print(data['audio'].shape)\n",
    "    waveform = data['audio'][0, start: end]\n",
    "    print(duration)\n",
    "    print(data['chinese'], chinese, time, ''.join(data['phoneme'][idx]))\n",
    "    play(waveform)\n",
    "    print('%.2f' % duration[0])\n",
    "\n",
    "test_one_char(train_set[5], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "靠耳朵听，发现大部分的标注是准确的，也有小部分划分有点出入。\n",
    "文本注音也有些问题，但是问题不大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "这儿我们制作一个单个字的dataloader，包含拼音、音调、时常（量化后），延音。\n",
    "\n",
    "之后使用lookup emb制作decoder的输入emb。这儿注意可以使用前一个字后一个字来辅助生成更好的声音。如果这样做，注意前一个字，本字，后一个字都需要使用不同的lookup table。\n",
    "\n",
    "先做一个naive版本，前后一个字不考虑。即使如此，我们的dataloader任然需要提供所有信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['audio', 'text', 'chinese', 'phoneme', 'note', 'duration', 'slur'])\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "class MusicLoaderGenerator:\n",
    "    def __init__(self, \n",
    "        labels,\n",
    "        num_workers=0,\n",
    "        sample_rate = 22050,\n",
    "        min_range = 512 * 4, # 默认删除过短的音频\n",
    "        max_range = 4 * 22050, # 默认删除4秒以上长度的音频\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ) -> None:\n",
    "        self.min_range, self.max_range = min_range, max_range\n",
    "        self.phoneme_labels, self.note_labels, self.slur_labels = labels\n",
    "        self.phoneme_look_up = {s: i for i, s in enumerate(self.phoneme_labels)}\n",
    "        self.note_look_up = {s: i for i, s in enumerate(self.note_labels)}\n",
    "        self.slur_look_up = {s: i for i, s in enumerate(self.slur_labels)}\n",
    "        self.device = device\n",
    "        self.num_workers = num_workers\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\\\n",
    "            n_fft=1024,power=1,hop_length=256,win_length=1024, n_mels=80, \\\n",
    "                f_min=0.0, f_max=8000.0, mel_scale=\"slaney\", norm=\"slaney\")\n",
    "        self.version = '0.01'\n",
    "\n",
    "    def label2id(self, look_up, str):\n",
    "        if isinstance(str[0], list):\n",
    "            return torch.stack([torch.tensor([look_up[i] for i in sub]) for sub in str])\n",
    "        return torch.tensor([look_up[i] for i in str])\n",
    "\n",
    "    def id2label(self, labels, idcs):\n",
    "        return ''.join([labels[i] for i in idcs])\n",
    "\n",
    "    def quant(self, duration):\n",
    "        min_seg = 512/22050\n",
    "        if duration < 2:\n",
    "            return int(duration//min_seg)\n",
    "        return int(2//min_seg + (duration-2)//(min_seg*2))\n",
    "\n",
    "\n",
    "    def collate_wrapper(self, batch:list): # RAW\n",
    "        bs = len(batch)\n",
    "        sample_rate = self.sample_rate\n",
    "        audio, audio_len, audio_duration, audio_duration_quant, chinese, phoneme,\\\n",
    "            phoneme_pre, phoneme_post, note, note_pre, note_post, slur,\\\n",
    "                mel, mel_len = [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "        safe_log = lambda x: torch.log(x+2**(-15))\n",
    "        for data in batch:\n",
    "            audio_f = data['audio']\n",
    "            chinese_f = data['chinese']\n",
    "            phoneme_f = data['phoneme']\n",
    "            note_f = data['note']\n",
    "            duration_f = data['duration']\n",
    "            duration_cum = duration_f.copy()\n",
    "            for i in range(1, len(duration_cum)):\n",
    "                duration_cum[i] += duration_cum[i-1]\n",
    "            slur_f = data['slur']\n",
    "            for i in range(len(chinese_f)):\n",
    "                start = 0 if i == 0 else int(duration_cum[i-1]*sample_rate)\n",
    "                end = int(duration_cum[i]*sample_rate)\n",
    "                if end-start<self.min_range or end-start>self.max_range:\n",
    "                    continue\n",
    "                wave_chunk = audio_f[0, start: end]\n",
    "                audio.append(wave_chunk)\n",
    "                audio_len.append(len(wave_chunk))\n",
    "                audio_duration.append(duration_f[i])\n",
    "                audio_duration_quant.append(self.quant(duration_f[i]))\n",
    "                chinese.append(chinese_f[i])\n",
    "                phoneme.append(phoneme_f[i])\n",
    "                phoneme_pre.append(phoneme_f[i-1]if i>0 else ['SP', '-'])\n",
    "                phoneme_post.append(phoneme_f[i+1]if i+1<len(phoneme_f) else ['SP', '-'])\n",
    "                note.append(note_f[i])\n",
    "                note_pre.append(note_f[i-1]if i>0 else 'rest')\n",
    "                note_post.append(note_f[i+1]if i+1<len(note_f) else 'rest')\n",
    "                slur.append(slur_f[i])\n",
    "                mel_chunk = self.mel_transform(wave_chunk)\n",
    "                mel.append(safe_log(mel_chunk).transpose(0,1))\n",
    "                mel_len.append(mel_chunk.shape[-1])\n",
    "        mel = pad_sequence(mel, batch_first=True, padding_value=torch.log(torch.tensor(2**(-15)))).permute(0,2,1)\n",
    "        mel_len = torch.tensor(mel_len)\n",
    "        \n",
    "        return {\n",
    "            'audio': audio,  # 单个字的raw音频\n",
    "            'audio_len': audio_len, # 该音频数据长度\n",
    "            'audio_duration': audio_duration, # 真实音屏时间长度\n",
    "            'audio_duration_quant': torch.tensor(audio_duration_quant), # 量化后音屏时间长度\n",
    "            'chinese': chinese, # 该音频汉字\n",
    "            'phoneme': self.label2id(self.phoneme_look_up, phoneme), # 拼音\n",
    "            'phoneme_pre': self.label2id(self.phoneme_look_up, phoneme_pre), # 前一个汉字的拼音\n",
    "            'phoneme_post': self.label2id(self.phoneme_look_up, phoneme_post), # 后一个汉字的拼音\n",
    "            'note': self.label2id(self.note_look_up, note), # 音调音符\n",
    "            'note_pre': self.label2id(self.note_look_up, note_pre),\n",
    "            'note_post': self.label2id(self.note_look_up, note_post),\n",
    "            'slur': self.label2id(self.slur_look_up, slur), # 是否为延长音\n",
    "            'mel': mel,\n",
    "            'mel_len': mel_len\n",
    "            }\n",
    "\n",
    "    def dataloader(self, audioDataset, batch_size, shuffle=True):\n",
    "        # k_size is the kernel size for the encoder, for data augmentation\n",
    "        self.threshold = audioDataset.dataset.threshold\n",
    "        return DataLoader(audioDataset, batch_size,\n",
    "                            shuffle, num_workers=self.num_workers, collate_fn=self.collate_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_pitch_labels\n",
    "note_labels = get_pitch_labels()\n",
    "slur_labels = [0, 1]\n",
    "# 0-1 分辨率0.01，1-2 分辨率0.05，2-7 分辨率0.2\n",
    "duration_labels = [i for i in range(130)] # max_note_duration is 6.x s, so we set max is 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 3744 test_set: 12\n",
      "['在', '我', '感', '情', '的', '封', '锁', '区', '~', 'AP', '有', '关', '于', '你', 'AP', '它', '让', '我', '在', '夜', '里', 'SP', '不', '会', '冷', 'SP', 'AP']\n",
      "torch.Size([27, 2])\n",
      "tensor([20, 16, 14, 19, 12, 26, 18, 16, 10,  9, 14, 18, 11, 60, 14, 20, 10, 15,\n",
      "        22,  7, 12,  4, 16, 27, 59, 21, 16])\n",
      "torch.Size([27])\n",
      "torch.Size([27, 80, 122])\n",
      "torch.Size([27]) tensor([ 42,  33,  30,  39,  25,  53,  37,  33,  22,  19,  29,  37,  23, 122,\n",
      "         30,  42,  22,  31,  46,  15,  26,  10,  34,  55, 120,  43,  33])\n"
     ]
    }
   ],
   "source": [
    "labels = (\n",
    "    phoneme_labels,\n",
    "    note_labels,\n",
    "    slur_labels\n",
    ")\n",
    "loaderGenerator = MusicLoaderGenerator(labels)\n",
    "train_loader = loaderGenerator.dataloader(train_set, batch_size=2)\n",
    "print('train_set:', len(train_set), 'test_set:',len(test_set))\n",
    "steps = 1\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    if steps <= 0:\n",
    "        break\n",
    "    print(sample_batched['chinese'])\n",
    "    print(sample_batched['phoneme'].shape)\n",
    "    print(sample_batched['audio_duration_quant'])\n",
    "    print(sample_batched['note_post'].shape)\n",
    "    print(sample_batched['mel'].shape)\n",
    "    print(sample_batched['mel_len'].shape, sample_batched['mel_len'])\n",
    "    steps -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用解码器mel2audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bh2283/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/home/bh2283/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/home/bh2283/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/home/bh2283/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py:55: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755832681/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:1980.)\n",
      "  W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveglow = torch.hub.load(\n",
    "    \"NVIDIA/DeepLearningExamples:torchhub\",\n",
    "    \"nvidia_waveglow\",\n",
    "    model_math=\"fp32\",\n",
    "    pretrained=False,\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "checkpoint = torch.hub.load_state_dict_from_url(\n",
    "    \"https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth\",  # noqa: E501\n",
    "    progress=False,\n",
    "    map_location=device,\n",
    ")\n",
    "state_dict = {key.replace(\"module.\", \"\"): value for key, value in checkpoint[\"state_dict\"].items()}\n",
    "waveglow.load_state_dict(state_dict)\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to(device)\n",
    "waveglow.eval()\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 81486])\n",
      "mel torch.Size([80, 44])\n",
      "torch.Size([80, 44])\n",
      "['就', '算', '是', '我', 'SP', '不', 'SP', '懂', 'AP', 'SP'] 是 0.50878 shi\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_one_char(data, idx, sample_rate = sample_rate):\n",
    "    assert idx < len(data['chinese'])\n",
    "    chinese = data['chinese'][idx]\n",
    "    time = data['duration'][idx]\n",
    "    duration = data['duration']\n",
    "    for i in range(1, len(duration)):\n",
    "        duration[i] += duration[i-1]\n",
    "    start = 0 if idx == 0 else int(duration[idx-1]*sample_rate)\n",
    "    end = int(duration[idx]*sample_rate)\n",
    "    print(data['audio'].shape)\n",
    "    waveform = data['audio'][0, start: end]\n",
    "    play(waveform)\n",
    "    \n",
    "    mel = mel_transform(waveform)\n",
    "    mel = torch.log(mel+2**(-15))\n",
    "    # plt.imshow(mel.detach().numpy(), interpolation='none')\n",
    "    print(mel.shape)\n",
    "    # with torch.no_grad():\n",
    "    waveforms = waveglow.infer(mel.unsqueeze(0))\n",
    "    # plt.plot(waveforms[0].cpu().detach())\n",
    "    plt.imshow(mel_transform(waveforms[0]).detach().numpy(), interpolation='none')\n",
    "    print(data['chinese'], chinese, time, ''.join(data['phoneme'][idx]))\n",
    "    torchaudio.save(\"my_output_waveglow.wav\", waveforms[0:1].cpu(), sample_rate=sample_rate)\n",
    "\n",
    "test_one_char(train_set[13], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3322949f56cb4db99427e05ed2d4a87f0497ffa3e41dd81b99d577253bd3be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
