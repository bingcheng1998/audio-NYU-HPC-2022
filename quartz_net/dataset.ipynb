{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_initial_table, get_final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语音数据集预处理\n",
    "\n",
    "- 将连续的多音节重叠到一起，划分单个汉字的时间\n",
    "- 延长发音需要标注出来，确定为延长，方便之后生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_table = get_initial_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(x): \n",
    "    for s in x:\n",
    "        print(len(s), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcriptions(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        if (lines[-1]==''):\n",
    "            lines = lines[:-1]\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/opencpop/segments/'\n",
    "lines = get_transcriptions(path+'train.txt')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(id, path, sr = 16000):\n",
    "    wav_path = path+'wavs/'+str(id)+'.wav'\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    if sample_rate != sr:\n",
    "        waveform = torchaudio.functional.resample(waveform[0].unsqueeze(0), sample_rate, sr)\n",
    "    return waveform\n",
    "\n",
    "def parser_line(line):\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = line.split('|')\n",
    "    phoneme = phoneme.split(' ')\n",
    "    note = note.split(' ')\n",
    "    note_duration = [float(i) for i in note_duration.split(' ')]\n",
    "    phoneme_duration = [float(i) for i in phoneme_duration.split(' ')]\n",
    "    slur_note = [int(i) for i in slur_note.split(' ')]\n",
    "    assert len(phoneme) == len(note_duration) and len(phoneme_duration) == len(slur_note) and len(slur_note) == len(phoneme)\n",
    "    return id, text, phoneme, note, note_duration, phoneme_duration, slur_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看下一共用到了多少元音辅音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'到现在'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_set = set()\n",
    "note_set = set()\n",
    "min_note_duration = 100\n",
    "max_note_duration = -1\n",
    "note_durations = []\n",
    "for line in lines:\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(line)\n",
    "    phoneme_set.update(set(phoneme))\n",
    "    note_set.update(set(note))\n",
    "    note_durations.extend(note_duration)\n",
    "    if max(note_duration) > max_note_duration:\n",
    "        max_note_duration = max(note_duration)\n",
    "        max_note_id = text\n",
    "    if min(note_duration) < min_note_duration:\n",
    "        min_note_duration = min(note_duration)\n",
    "\n",
    "max_note_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要依赖下图进行时间分辨率量化embedding。\n",
    "\n",
    "在0-1之间，密集，所以需要精细的分辨率，比如0.01，之后可以降低分辨率，比如改为0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(note_durations, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 {'uai', 'ian', 'm', 'q', 'ong', 'ao', 'b', 'e', 'ie', 'r', 'a', 'iong', 'ua', 'AP', 'ou', 'iang', 'ia', 'd', 'iu', 'u', 'iao', 'p', 'uang', 't', 'ai', 'van', 'in', 'ei', 'k', 'ang', 'ch', 'v', 's', 'an', 'ui', 'h', 'sh', 'eng', 'uo', 'w', 'un', 'j', 'g', 'n', 'i', 'ing', 'y', 'SP', 'uan', 'zh', 'x', 'c', 'er', 'o', 'z', 'vn', 've', 'f', 'en', 'l'}\n",
      "35 {'B4', 'C4', 'F3', 'F5', 'E3', 'E4', 'G3', 'A5', 'G#4/Ab4', 'A4', 'A#3/Bb3', 'B3', 'F#4/Gb4', 'D4', 'D#5/Eb5', 'F#3/Gb3', 'C5', 'E5', 'C#5/Db5', 'A#4/Bb4', 'D#3/Eb3', 'C#3/Db3', 'F#5/Gb5', 'D3', 'D2', 'F4', 'G4', 'C#2/Db2', 'C3', 'D5', 'rest', 'C#4/Db4', 'A3', 'D#4/Eb4', 'G#3/Ab3'}\n",
      "6.35453 0.0071\n"
     ]
    }
   ],
   "source": [
    "print_all([phoneme_set,note_set])\n",
    "print(max_note_duration, min_note_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'-', 'iou', 'uei', 'uen', 'ueng', '|', 'ê'}, {'AP', 'SP', 'iu', 'ui', 'un'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import get_phoneme_labels\n",
    "phoneme_labels = get_phoneme_labels()\n",
    "set(phoneme_labels) - phoneme_set, phoneme_set - set(phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transposed_phoneme_labels():\n",
    "    phoneme_list = get_initial_table() + get_final_table()\n",
    "    for x in ['iou', 'uei', 'uen', 'ueng', 'ê']:\n",
    "        phoneme_list.remove(x)\n",
    "    phoneme_list += ['iu', 'ui', 'un', 'AP', 'SP']\n",
    "    return ['-', '|']+phoneme_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '|', 'b', 'p', 'm', 'f', 'd', 't', 'n', 'l', 'g', 'k', 'h', 'j', 'q', 'x', 'zh', 'ch', 'sh', 'r', 'z', 'c', 's', 'y', 'w', 'i', 'u', 'v', 'a', 'ia', 'ua', 'o', 'uo', 'e', 'ie', 've', 'ai', 'uai', 'ei', 'ao', 'iao', 'ou', 'an', 'ian', 'uan', 'van', 'en', 'in', 'vn', 'ang', 'iang', 'uang', 'eng', 'ing', 'ong', 'iong', 'er', 'iu', 'ui', 'un', 'AP', 'SP']\n"
     ]
    }
   ],
   "source": [
    "phoneme_labels = get_transposed_phoneme_labels()\n",
    "print(phoneme_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打一个示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2001000006|漂浮在一片无奈|p iao f u z ai ai ai AP SP y i i p ian ian ian w u n ai SP AP|E4 E4 F#4/Gb4 F#4/Gb4 G#4/Ab4 G#4/Ab4 A4 G#4/Ab4 rest rest E4 E4 F#4/Gb4 G#4/Ab4 G#4/Ab4 A4 G#4/Ab4 E4 E4 F#4/Gb4 F#4/Gb4 rest rest|0.185230 0.185230 0.177410 0.177410 0.193930 0.193930 0.259670 0.299340 0.215550 0.031770 0.197520 0.197520 0.165450 0.184760 0.184760 0.212290 0.246960 0.440370 0.440370 1.524950 1.524950 0.855830 0.559100|0.06011 0.12512 0.07517 0.10224 0.08603 0.1079 0.25967 0.29934 0.21555 0.03177 0.05175 0.14577 0.16545 0.0748 0.10996 0.21229 0.24696 0.09617 0.3442 0.1437 1.38125 0.85583 0.5591|0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = lines[5]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2001000006\n",
      "7 漂浮在一片无奈\n",
      "23 ['p', 'iao', 'f', 'u', 'z', 'ai', 'ai', 'ai', 'AP', 'SP', 'y', 'i', 'i', 'p', 'ian', 'ian', 'ian', 'w', 'u', 'n', 'ai', 'SP', 'AP']\n",
      "23 ['E4', 'E4', 'F#4/Gb4', 'F#4/Gb4', 'G#4/Ab4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'rest', 'rest', 'E4', 'E4', 'F#4/Gb4', 'G#4/Ab4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'E4', 'E4', 'F#4/Gb4', 'F#4/Gb4', 'rest', 'rest']\n",
      "23 [0.18523, 0.18523, 0.17741, 0.17741, 0.19393, 0.19393, 0.25967, 0.29934, 0.21555, 0.03177, 0.19752, 0.19752, 0.16545, 0.18476, 0.18476, 0.21229, 0.24696, 0.44037, 0.44037, 1.52495, 1.52495, 0.85583, 0.5591]\n",
      "23 [0.06011, 0.12512, 0.07517, 0.10224, 0.08603, 0.1079, 0.25967, 0.29934, 0.21555, 0.03177, 0.05175, 0.14577, 0.16545, 0.0748, 0.10996, 0.21229, 0.24696, 0.09617, 0.3442, 0.1437, 1.38125, 0.85583, 0.5591]\n",
      "23 [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(line)\n",
    "print_all([id, text, phoneme, note, note_duration, phoneme_duration, slur_note])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音频文件读取测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 92003])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform = get_audio(id, path)\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "汉字元音辅音组合为单个汉字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'u', 'v', 'a', 'ia', 'ua', 'o', 'uo', 'e', 'ie', 've', 'ai', 'uai', 'ei', 'uei', 'ao', 'iao', 'ou', 'iou', 'an', 'ian', 'uan', 'van', 'en', 'in', 'uen', 'vn', 'ang', 'iang', 'uang', 'eng', 'ing', 'ueng', 'ong', 'iong', 'er', 'ê']\n"
     ]
    }
   ],
   "source": [
    "print(get_final_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_note(text, phoneme, note, note_duration, slur_note):\n",
    "    # 1. check whether the phoneme is in finals\n",
    "    INITIALS = get_initial_table()\n",
    "    FINALS = get_final_table()\n",
    "    # is_final = [1 if p in FINALS else 0 for p in phoneme]\n",
    "    phoneme = phoneme.copy()\n",
    "    note = note.copy()\n",
    "    note_duration = note_duration.copy()\n",
    "    slur_note = slur_note.copy()\n",
    "    j = -1\n",
    "    text+='////////////////////'\n",
    "    text_with_p = phoneme.copy()\n",
    "    used_flag = False\n",
    "    for i in range(len(text_with_p)):\n",
    "        if text_with_p[i] in ['AP', 'SP']:\n",
    "            continue\n",
    "        if j==-1 or phoneme[i] in INITIALS or (phoneme[i-1] not in INITIALS and phoneme[i] != phoneme[i-1]):\n",
    "            j+=1\n",
    "            used_flag = False\n",
    "        text_with_p[i] = text[j] if used_flag == False else '~'\n",
    "        used_flag = True\n",
    "    for i in range(len(phoneme)-1, 0, -1):\n",
    "        if (note_duration[i] == note_duration[i-1] and phoneme[i-1] in INITIALS):\n",
    "            del note_duration[i]\n",
    "            del note[i]\n",
    "            phoneme[i-1]=[phoneme[i-1],phoneme[i]]\n",
    "            del phoneme[i]\n",
    "            del text_with_p[i]\n",
    "            del slur_note[i]\n",
    "        elif phoneme[i] in FINALS or phoneme[i] in ['AP', 'SP']:\n",
    "            phoneme[i] = [phoneme[i], '-']\n",
    "    return text_with_p, phoneme, note, note_duration, slur_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['漂', '浮', '在', '~', '~', 'AP', 'SP', '一', '~', '片', '~', '~', '无', '奈', 'SP', 'AP']\n",
      "16 [['p', 'iao'], ['f', 'u'], ['z', 'ai'], ['ai', '-'], ['ai', '-'], ['AP', '-'], ['SP', '-'], ['y', 'i'], ['i', '-'], ['p', 'ian'], ['ian', '-'], ['ian', '-'], ['w', 'u'], ['n', 'ai'], ['SP', '-'], ['AP', '-']]\n",
      "16 ['E4', 'F#4/Gb4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'rest', 'rest', 'E4', 'F#4/Gb4', 'G#4/Ab4', 'A4', 'G#4/Ab4', 'E4', 'F#4/Gb4', 'rest', 'rest']\n",
      "16 [0.18523, 0.17741, 0.19393, 0.25967, 0.29934, 0.21555, 0.03177, 0.19752, 0.16545, 0.18476, 0.21229, 0.24696, 0.44037, 1.52495, 0.85583, 0.5591]\n",
      "16 [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_all(merge_note(text, phoneme, note, note_duration, slur_note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SpeechDataset\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpencpopDataset(SpeechDataset):\n",
    "\n",
    "    def __init__(self, data_path, sample_rate=16000, transform=None):\n",
    "        super().__init__(data_path, sample_rate, transform)\n",
    "        transcript_file = data_path+'transcriptions.txt'\n",
    "        self.transcript = self.gen_transcript(transcript_file)\n",
    "        self.dataset_file_num = len(self.transcript)\n",
    "        self.threshold = 120000 # to avoid GPU memory used out\n",
    "        self.batch_size = 80 # to avoid GPU memory used out\n",
    "        self.split_ratio = [1000, 3]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_file_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if idx >= self.dataset_file_num:\n",
    "            return {'audio': None, 'text': None}\n",
    "        line = self.transcript[idx]\n",
    "        id, text, phoneme, note, note_duration, phoneme_duration, slur_note = self.parser_line(line)\n",
    "        waveform = self.get_audio(id)\n",
    "        # text_with_p, phoneme, note, note_duration = merge_note(text, phoneme, note, note_duration)\n",
    "        sample = {'audio': waveform, 'text': line}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample, self.sample_rate)\n",
    "        return sample\n",
    "\n",
    "    def get_audio(self, id):\n",
    "        wav_path = self.data_path+'wavs/'+str(id)+'.wav'\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        if sample_rate != self.sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform[0].unsqueeze(0), sample_rate, self.sample_rate)\n",
    "        return waveform\n",
    "\n",
    "    def parser_line(self, line):\n",
    "        id, text, phoneme, note, note_duration, phoneme_duration, slur_note = line.split('|')\n",
    "        phoneme = phoneme.split(' ')\n",
    "        note = note.split(' ')\n",
    "        note_duration = [float(i) for i in note_duration.split(' ')]\n",
    "        phoneme_duration = [float(i) for i in phoneme_duration.split(' ')]\n",
    "        slur_note = [int(i) for i in slur_note.split(' ')]\n",
    "        assert len(phoneme) == len(note_duration) and len(phoneme_duration) == len(slur_note) and len(slur_note) == len(phoneme)\n",
    "        return id, text, phoneme, note, note_duration, phoneme_duration, slur_note\n",
    "\n",
    "    def gen_transcript(self, transcript_file):\n",
    "        with open(transcript_file) as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            if (lines[-1]==''):\n",
    "                lines = lines[:-1]\n",
    "            return lines\n",
    "\n",
    "    def split(self, split_ratio=None, seed=42):\n",
    "        audio_dataset = self\n",
    "        size = len(audio_dataset)\n",
    "        my_split_ratio = self.split_ratio if split_ratio is None else split_ratio\n",
    "        lengths = [(i*size)//sum(my_split_ratio) for i in my_split_ratio]\n",
    "        lengths[-1] = size - sum(lengths[:-1])\n",
    "        split_dataset = random_split(audio_dataset, lengths, generator=torch.Generator().manual_seed(seed))\n",
    "        return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataset_transform(sample, sample_rate=None):\n",
    "    id, text, phoneme, note, note_duration, phoneme_duration, slur_note = parser_line(sample['text'])\n",
    "    text_with_p, phoneme, note, note_duration, slur_note = merge_note(text, phoneme, note, note_duration, slur_note)\n",
    "    sample['chinese'] = text_with_p\n",
    "    sample['phoneme'] = phoneme\n",
    "    sample['note'] = note\n",
    "    sample['duration'] = note_duration\n",
    "    sample['slur'] = slur_note\n",
    "    return sample\n",
    "\n",
    "dataset = OpencpopDataset('/scratch/bh2283/data/opencpop/segments/', transform=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([[-0.0005, -0.0008, -0.0008,  ...,  0.0003,  0.0003,  0.0003]])\n",
      "514 2001000002|如何瞬间冻结时间|r u h e sh un j ian AP SP d ong j ie sh i j ian SP|B3 B3 B3 B3 B3 B3 G#4/Ab4 G#4/Ab4 rest rest B3 B3 B3 B3 B3 B3 F#4/Gb4 F#4/Gb4 rest|0.294760 0.294760 0.283550 0.283550 0.795250 0.795250 0.992200 0.992200 0.297130 0.104830 0.311040 0.311040 0.214620 0.214620 0.782750 0.782750 1.519540 1.519540 1.179120|0.06588 0.22888 0.11684 0.16671 0.18746 0.60779 0.11194 0.88026 0.29713 0.10483 0.03166 0.27938 0.05057 0.16405 0.21149 0.57126 0.13926 1.38028 1.17912|0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11 ['如', '何', '瞬', '间', 'AP', 'SP', '冻', '结', '时', '间', 'SP']\n",
      "11 [['r', 'u'], ['h', 'e'], ['sh', 'un'], ['j', 'ian'], ['AP', '-'], ['SP', '-'], ['d', 'ong'], ['j', 'ie'], ['sh', 'i'], ['j', 'ian'], ['SP', '-']]\n",
      "11 ['B3', 'B3', 'B3', 'G#4/Ab4', 'rest', 'rest', 'B3', 'B3', 'B3', 'F#4/Gb4', 'rest']\n",
      "11 [0.29476, 0.28355, 0.79525, 0.9922, 0.29713, 0.10483, 0.31104, 0.21462, 0.78275, 1.51954, 1.17912]\n",
      "11 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_all(dataset[1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3744, 12)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = dataset.split()\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单个字测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(waveform):\n",
    "    torchaudio.save('./audio-temp.wav', waveform.unsqueeze(0), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 99361])\n",
      "[0.39009, 0.76237, 1.1684299999999999, 1.4763199999999999, 2.06518, 2.5804, 3.4135400000000002, 5.350750000000001, 5.77657, 6.210050000000001]\n",
      "['一', '起', '看', '晚', '霞', '~', '满', '天', 'SP', 'AP'] AP 0.43348 AP-\n",
      "0.39\n"
     ]
    }
   ],
   "source": [
    "def test_one_char(data, idx, sample_rate = 16000):\n",
    "    assert idx < len(data['chinese'])\n",
    "    chinese = data['chinese'][idx]\n",
    "    time = data['duration'][idx]\n",
    "    duration = data['duration']\n",
    "    for i in range(1, len(duration)):\n",
    "        duration[i] += duration[i-1]\n",
    "    start = 0 if idx == 0 else int(duration[idx-1]*sample_rate)\n",
    "    end = int(duration[idx]*sample_rate)\n",
    "    print(data['audio'].shape)\n",
    "    waveform = data['audio'][0, start: end]\n",
    "    print(duration)\n",
    "    print(data['chinese'], chinese, time, ''.join(data['phoneme'][idx]))\n",
    "    play(waveform)\n",
    "    print('%.2f' % duration[0])\n",
    "\n",
    "test_one_char(train_set[5], 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "靠耳朵听，发现大部分的标注是准确的，也有小部分划分有点出入。\n",
    "文本注音也有些问题，但是问题不大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "这儿我们制作一个单个字的dataloader，包含拼音、音调、时常（量化后），延音。\n",
    "\n",
    "之后使用lookup emb制作decoder的输入emb。这儿注意可以使用前一个字后一个字来辅助生成更好的声音。如果这样做，注意前一个字，本字，后一个字都需要使用不同的lookup table。\n",
    "\n",
    "先做一个naive版本，前后一个字不考虑。即使如此，我们的dataloader任然需要提供所有信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['audio', 'text', 'chinese', 'phoneme', 'note', 'duration', 'slur'])\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLoaderGenerator:\n",
    "    def __init__(self, \n",
    "        labels,\n",
    "        num_workers=0,\n",
    "        sample_rate = 16000,\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ) -> None:\n",
    "        self.phoneme_labels, self.note_labels, self.duration_labels, self.slur_labels = labels\n",
    "        self.phoneme_look_up = {s: i for i, s in enumerate(self.phoneme_labels)}\n",
    "        self.note_look_up = {s: i for i, s in enumerate(self.note_labels)}\n",
    "        self.duration_look_up = {s: i for i, s in enumerate(self.duration_labels)}\n",
    "        self.slur_look_up = {s: i for i, s in enumerate(self.slur_labels)}\n",
    "        self.device = device\n",
    "        self.num_workers = num_workers\n",
    "        self.sample_rate = sample_rate\n",
    "        self.version = '0.01'\n",
    "\n",
    "    def label2id(self, look_up, str):\n",
    "        if isinstance(str[0], list):\n",
    "            return [[look_up[i] for i in sub] for sub in str]\n",
    "        return [look_up[i] for i in str]\n",
    "\n",
    "    def id2label(self, labels, idcs):\n",
    "        return ''.join([labels[i] for i in idcs])\n",
    "\n",
    "    def collate_wrapper(self, batch:list): # RAW\n",
    "        bs = len(batch)\n",
    "        sample_rate = self.sample_rate\n",
    "        audio, audio_len, audio_duration, audio_duration_quant, chinese, phoneme,\\\n",
    "            phoneme_pre, phoneme_post, note, note_pre, note_post, slur = [], [], [], [], [], [], [], [], [], [], [], []\n",
    "        for data in batch:\n",
    "            audio_f = data['audio']\n",
    "            chinese_f = data['chinese']\n",
    "            phoneme_f = data['phoneme']\n",
    "            note_f = data['note']\n",
    "            duration_f = data['duration']\n",
    "            duration_cum = duration_f.copy()\n",
    "            for i in range(1, len(duration_cum)):\n",
    "                duration_cum[i] += duration_cum[i-1]\n",
    "            slur_f = data['slur']\n",
    "            for i in range(len(chinese_f)):\n",
    "                start = 0 if i == 0 else int(duration_cum[i-1]*sample_rate)\n",
    "                end = int(duration_cum[i]*sample_rate)\n",
    "                wave_chunk = audio_f[0, start: end]\n",
    "                audio.append(wave_chunk)\n",
    "                audio_len.append(len(wave_chunk))\n",
    "                audio_duration.append(duration_f[i])\n",
    "                audio_duration_quant.append('%.2f' % duration_f[i])\n",
    "                chinese.append(chinese_f[i])\n",
    "                phoneme.append(phoneme_f[i])\n",
    "                phoneme_pre.append(phoneme_f[i-1]if i>0 else ['SP'])\n",
    "                phoneme_post.append(phoneme_f[i+1]if i+1<len(phoneme_f) else ['SP'])\n",
    "                note.append(note_f[i])\n",
    "                note_pre.append(note_f[i-1]if i>0 else 'rest')\n",
    "                note_post.append(note_f[i+1]if i+1<len(note_f) else 'rest')\n",
    "                slur.append(slur_f[i])\n",
    "        \n",
    "        return {\n",
    "            'audio': audio,  # 单个字的raw音频\n",
    "            'audio_len': audio_len, # 该音频数据长度\n",
    "            'audio_duration': audio_duration, # 真实音屏时间长度\n",
    "            'audio_duration_quant': audio_duration_quant, # 量化后音屏时间长度\n",
    "            'chinese': chinese, # 该音频汉字\n",
    "            'phoneme': self.label2id(self.phoneme_look_up, phoneme), # 拼音\n",
    "            'phoneme_pre': self.label2id(self.phoneme_look_up, phoneme_pre), # 前一个汉字的拼音\n",
    "            'phoneme_post': self.label2id(self.phoneme_look_up, phoneme_post), # 后一个汉字的拼音\n",
    "            'note': self.label2id(self.note_look_up, note), # 音调音符\n",
    "            'note_pre': self.label2id(self.note_look_up, note_pre),\n",
    "            'note_post': self.label2id(self.note_look_up, note_post),\n",
    "            'slur': self.label2id(self.slur_look_up, slur), # 是否为延长音\n",
    "            }\n",
    "\n",
    "    def dataloader(self, audioDataset, batch_size, shuffle=True):\n",
    "        # k_size is the kernel size for the encoder, for data augmentation\n",
    "        self.threshold = audioDataset.dataset.threshold\n",
    "        return DataLoader(audioDataset, batch_size,\n",
    "                            shuffle, num_workers=self.num_workers, collate_fn=self.collate_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_pitch_labels\n",
    "note_labels = get_pitch_labels()\n",
    "slur_labels = [0, 1]\n",
    "# 0-1 分辨率0.01，1-2 分辨率0.05，2-7 分辨率0.2\n",
    "duration_labels = [i for i in range(7)] # max_note_duration is 6.x s, so we set max is 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 3744 test_set: 12\n",
      "['世', '事', '如', '烟', '云', '易', '改', '~', '~', '~', '在', '旧', '时', '亭', '~', '台', '~', 'SP', 'AP', '我', '失', 'SP', '去', '你', '~', '~']\n",
      "[[18, 25], [18, 25], [19, 26], [23, 42], [23, 48], [23, 25], [10, 36], [36, 0], [36, 0], [36, 0], [20, 36], [13, 57], [18, 25], [7, 53], [53, 0], [7, 36], [36, 0], [61, 0], [60, 0], [24, 31], [18, 25], [61, 0], [14, 27], [8, 25], [25, 0], [25, 0]]\n"
     ]
    }
   ],
   "source": [
    "labels = (\n",
    "    phoneme_labels,\n",
    "    note_labels,\n",
    "    duration_labels,\n",
    "    slur_labels\n",
    ")\n",
    "loaderGenerator = MusicLoaderGenerator(labels)\n",
    "train_loader = loaderGenerator.dataloader(train_set, batch_size=2)\n",
    "print('train_set:', len(train_set), 'test_set:',len(test_set))\n",
    "steps = 1\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    if steps <= 0:\n",
    "        break\n",
    "    print(sample_batched['chinese'])\n",
    "    print(sample_batched['phoneme'])\n",
    "    steps -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3322949f56cb4db99427e05ed2d4a87f0497ffa3e41dd81b99d577253bd3be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
