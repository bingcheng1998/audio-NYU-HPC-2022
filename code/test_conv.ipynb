{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "0.11.0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [16.0, 4.8]\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "print(device)\n",
    "\n",
    "SPEECH_URL = \"https://download.pytorch.org/torchaudio/tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "SPEECH_FILE = \"_assets/speech.wav\"\n",
    "\n",
    "if not os.path.exists(SPEECH_FILE):\n",
    "    os.makedirs(\"_assets\", exist_ok=True)\n",
    "    with open(SPEECH_FILE, \"wb\") as file:\n",
    "        file.write(requests.get(SPEECH_URL).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 54400])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform, _ = torchaudio.load(SPEECH_FILE)\n",
    "waveform = waveform.unsqueeze(0)\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 10879])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
    "o = m(waveform.to(device))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 3, 0, 8, 1, 4, 3, 7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(10, (8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 10879])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm = nn.GroupNorm(512, 512, eps=1e-05, affine=True) # Instance Norm, splite 512 channels to 512 groups\n",
    "layer_norm(o).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=3\n",
    "T=2\n",
    "input_lengths = torch.tensor(T, dtype=torch.long)\n",
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3322949f56cb4db99427e05ed2d4a87f0497ffa3e41dd81b99d577253bd3be5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
