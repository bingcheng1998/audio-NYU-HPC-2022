{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import dtype\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchaudio\n",
    "\n",
    "class AiShellDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path, sample_rate=16000, transform=None):\n",
    "        transcript_file = data_path+'transcript/aishell_transcript_v0.8.txt'\n",
    "        self.transcript = self.gen_transcript(transcript_file)\n",
    "        self.wav_files = self.get_all_wav_files(data_path, self.transcript)\n",
    "        self.dataset_file_num = len(self.wav_files)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.threshold = 120000 # to avoid GPU memory used out\n",
    "        self.batch_size = 80 # to avoid GPU memory used out\n",
    "        self.split_ratio = [1000, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_file_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if idx >= self.dataset_file_num:\n",
    "            return {'audio': None, 'text': None}\n",
    "        audio_name = self.wav_files[idx]\n",
    "        waveform, sample_rate = torchaudio.load(audio_name)\n",
    "        waveform = waveform\n",
    "        if sample_rate != self.sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform, sample_rate, self.sample_rate)\n",
    "        dict_id = audio_name.rsplit('/',1)[-1].split('.')[0]\n",
    "        audio_content = self.transcript[dict_id]\n",
    "        sample = {'audio': waveform, 'text': audio_content}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def parse_line(self, line):\n",
    "        id, text = line.split(' ', 1)\n",
    "        text = ''.join(text.split(' '))\n",
    "        return id, text\n",
    "\n",
    "    def gen_transcript(self, transcript_file):\n",
    "        transcript = {}\n",
    "        with open(transcript_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            lines = content.split('\\n')[:-1]\n",
    "            for line in lines:\n",
    "                id, text = self.parse_line(line)\n",
    "                transcript[id] = text\n",
    "        return transcript\n",
    "\n",
    "    def get_all_wav_files(self, path, transcript):\n",
    "        folders = []\n",
    "        train = os.listdir(path+'wav/train/')\n",
    "        folders += [path+'wav/train/'+i for i in train]\n",
    "        dev = os.listdir(path+'wav/dev/')\n",
    "        folders += [path+'wav/dev/'+i for i in dev]\n",
    "        test = os.listdir(path+'wav/test/')\n",
    "        folders += [path+'wav/test/'+i for i in test]\n",
    "        files = []\n",
    "        for folder in folders:\n",
    "            files += [folder+'/'+i for i in os.listdir(folder) if i[:-4] in transcript]\n",
    "        return files\n",
    "    \n",
    "    def split(self, split_ratio=None, seed=42):\n",
    "        audio_dataset = self\n",
    "        size = len(audio_dataset)\n",
    "        my_split_ratio = self.split_ratio if split_ratio is None else split_ratio\n",
    "        lengths = [(i*size)//sum(my_split_ratio) for i in my_split_ratio]\n",
    "        lengths[-1] = size - sum(lengths[:-1])\n",
    "        split_dataset = random_split(audio_dataset, lengths, generator=torch.Generator().manual_seed(seed))\n",
    "        return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 140895 test_set: 705\n",
      "torch.Size([8, 88087]) torch.Size([8, 69])\n",
      "torch.Size([8, 96348]) torch.Size([8, 72])\n",
      "torch.Size([6, 86609]) torch.Size([6, 69])\n",
      "torch.Size([8, 97678]) torch.Size([8, 93])\n",
      "torch.Size([7, 85789]) torch.Size([7, 68])\n",
      "torch.Size([7, 95672]) torch.Size([7, 71])\n",
      "torch.Size([8, 104533]) torch.Size([8, 82])\n",
      "torch.Size([8, 106464]) torch.Size([8, 96])\n",
      "torch.Size([8, 112501]) torch.Size([8, 86])\n",
      "torch.Size([8, 99767]) torch.Size([8, 81])\n",
      "torch.Size([7, 87598]) torch.Size([7, 90])\n",
      "torch.Size([8, 82148]) torch.Size([8, 68])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # dataset = AudioDataset('./data/ST-CMDS-20170001_1-OS/')\n",
    "    dataset = AiShellDataset('./data/data_aishell/')\n",
    "    batch_size = 8\n",
    "    train_set, test_set = dataset.split([1000, 5])\n",
    "    k_size = 5 # kernel size for audio encoder\n",
    "    from pypinyin import lazy_pinyin\n",
    "    def chinese2pinyin(text):\n",
    "        pinyin = lazy_pinyin(text, strict=True,errors=lambda x: u'')\n",
    "        pinyin = [i for i in '|'.join(pinyin)]\n",
    "        return pinyin\n",
    "    from utils.helper import get_labels\n",
    "    from utils.dataset import LoaderGenerator\n",
    "    labels = get_labels()\n",
    "    loaderGenerator = LoaderGenerator(labels, chinese2pinyin, k_size)\n",
    "    train_loader = loaderGenerator.dataloader(train_set, batch_size)\n",
    "    test_loader = loaderGenerator.dataloader(test_set, batch_size) # without backprop, can use larger batch\n",
    "    print('train_set:', len(train_set), 'test_set:',len(test_set))\n",
    "    steps = 10\n",
    "    for i_batch, sample_batched in enumerate(test_loader):\n",
    "        print(sample_batched['audio'].shape, sample_batched['target'].shape)\n",
    "        # for i in sample_batched['audio']:\n",
    "        #     print(i.shape)\n",
    "        if steps < 0:\n",
    "            break\n",
    "        steps -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AiShellDataset('./data/data_aishell/')\n",
    "lens = [dataset[i]['audio'].shape[-1] for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens2 = [dataset[i+500]['audio'].shape[-1] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens+lens2, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3322949f56cb4db99427e05ed2d4a87f0497ffa3e41dd81b99d577253bd3be5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
