{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import dtype\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchaudio\n",
    "\n",
    "class AiShellDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path, sample_rate=16000, transform=None):\n",
    "        transcript_file = data_path+'transcript/aishell_transcript_v0.8.txt'\n",
    "        self.transcript = self.gen_transcript(transcript_file)\n",
    "        self.wav_files = self.get_all_wav_files(data_path, self.transcript)\n",
    "        self.dataset_file_num = len(self.wav_files)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.threshold = 120000 # to avoid GPU memory used out\n",
    "        self.batch_size = 80 # to avoid GPU memory used out\n",
    "        self.split_ratio = [1000, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_file_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if idx >= self.dataset_file_num:\n",
    "            return {'audio': None, 'text': None}\n",
    "        audio_name = self.wav_files[idx]\n",
    "        waveform, sample_rate = torchaudio.load(audio_name)\n",
    "        waveform = waveform\n",
    "        if sample_rate != self.sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform, sample_rate, self.sample_rate)\n",
    "        dict_id = audio_name.rsplit('/',1)[-1].split('.')[0]\n",
    "        audio_content = self.transcript[dict_id]\n",
    "        sample = {'audio': waveform, 'text': audio_content}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def parse_line(self, line):\n",
    "        id, text = line.split(' ', 1)\n",
    "        text = ''.join(text.split(' '))\n",
    "        return id, text\n",
    "\n",
    "    def gen_transcript(self, transcript_file):\n",
    "        transcript = {}\n",
    "        with open(transcript_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            lines = content.split('\\n')[:-1]\n",
    "            for line in lines:\n",
    "                id, text = self.parse_line(line)\n",
    "                transcript[id] = text\n",
    "        return transcript\n",
    "\n",
    "    def get_all_wav_files(self, path, transcript):\n",
    "        folders = []\n",
    "        train = os.listdir(path+'wav/train/')\n",
    "        folders += [path+'wav/train/'+i for i in train]\n",
    "        dev = os.listdir(path+'wav/dev/')\n",
    "        folders += [path+'wav/dev/'+i for i in dev]\n",
    "        test = os.listdir(path+'wav/test/')\n",
    "        folders += [path+'wav/test/'+i for i in test]\n",
    "        files = []\n",
    "        for folder in folders:\n",
    "            files += [folder+'/'+i for i in os.listdir(folder) if i[:-4] in transcript]\n",
    "        return files\n",
    "    \n",
    "    def split(self, split_ratio=None, seed=42):\n",
    "        audio_dataset = self\n",
    "        size = len(audio_dataset)\n",
    "        my_split_ratio = self.split_ratio if split_ratio is None else split_ratio\n",
    "        lengths = [(i*size)//sum(my_split_ratio) for i in my_split_ratio]\n",
    "        lengths[-1] = size - sum(lengths[:-1])\n",
    "        split_dataset = random_split(audio_dataset, lengths, generator=torch.Generator().manual_seed(seed))\n",
    "        return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 140895 test_set: 705\n",
      "torch.Size([8, 94301]) torch.Size([8, 82])\n",
      "torch.Size([7, 90778]) torch.Size([7, 75])\n",
      "torch.Size([8, 95557]) torch.Size([8, 90])\n",
      "torch.Size([8, 96123]) torch.Size([8, 89])\n",
      "torch.Size([8, 102204]) torch.Size([8, 95])\n",
      "torch.Size([6, 97673]) torch.Size([6, 93])\n",
      "torch.Size([8, 88088]) torch.Size([8, 76])\n",
      "torch.Size([8, 95365]) torch.Size([8, 75])\n",
      "torch.Size([7, 77399]) torch.Size([7, 67])\n",
      "torch.Size([8, 102859]) torch.Size([8, 73])\n",
      "torch.Size([8, 93783]) torch.Size([8, 78])\n",
      "torch.Size([8, 103609]) torch.Size([8, 82])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # dataset = AudioDataset('./data/ST-CMDS-20170001_1-OS/')\n",
    "    dataset = AiShellDataset('./data/data_aishell/')\n",
    "    batch_size = 8\n",
    "    train_set, test_set = dataset.split([1000, 5])\n",
    "    k_size = 5 # kernel size for audio encoder\n",
    "    from pypinyin import lazy_pinyin\n",
    "    def chinese2pinyin(text):\n",
    "        pinyin = lazy_pinyin(text, strict=True,errors=lambda x: u'')\n",
    "        pinyin = [i for i in '|'.join(pinyin)]\n",
    "        return pinyin\n",
    "    from utils.helper import get_labels\n",
    "    from utils.dataset import LoaderGenerator\n",
    "    labels = get_labels()\n",
    "    loaderGenerator = LoaderGenerator(labels, chinese2pinyin, k_size)\n",
    "    train_loader = loaderGenerator.dataloader(train_set, batch_size)\n",
    "    test_loader = loaderGenerator.dataloader(test_set, batch_size) # without backprop, can use larger batch\n",
    "    print('train_set:', len(train_set), 'test_set:',len(test_set))\n",
    "    steps = 10\n",
    "    for i_batch, sample_batched in enumerate(test_loader):\n",
    "        print(sample_batched['audio'].shape, sample_batched['target'].shape)\n",
    "        # for i in sample_batched['audio']:\n",
    "        #     print(i.shape)\n",
    "        if steps < 0:\n",
    "            break\n",
    "        steps -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AiShellDataset('./data/data_aishell/')\n",
    "lens = [dataset[i]['audio'].shape[-1] for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens2 = [dataset[i+500]['audio'].shape[-1] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens+lens2, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = './data/primewords_md_2018_set1/'\n",
    "with open(data_path+'set1_transcript.json') as f:\n",
    "   data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50902"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '64869',\n",
       " 'file': 'd6b26896-f2ef-4085-950d-47cd24f21d8f.wav',\n",
       " 'user_id': '1013',\n",
       " 'text': '于是 一切又重新开始 而这一来 我又忘记了它们',\n",
       " 'length': '8.64'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    return line['file'], line['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav(file_name):\n",
    "    path = data_path+'audio_files/'+file_name[0]+'/'+file_name[:2]+'/'+file_name\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "audio_name = get_wav(parse_line(data[0])[0])\n",
    "waveform, sample_rate = torchaudio.load(audio_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.0518e-05,\n",
       "         -6.1035e-05, -1.5259e-04]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import dtype\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchaudio\n",
    "\n",
    "class PrimeWordsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path, sample_rate=16000, transform=None):\n",
    "        with open(data_path+'set1_transcript.json') as f:\n",
    "            json_data = json.load(f)\n",
    "        self.json_data = json_data\n",
    "        # self.wav_files = self.get_all_wav_files(data_path, self.transcript)\n",
    "        self.dataset_file_num = len(self.json_data)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.threshold = 220000 # to avoid GPU memory used out\n",
    "        self.batch_size = 40 # to avoid GPU memory used out\n",
    "        self.split_ratio = [1000, 2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_file_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if idx >= self.dataset_file_num:\n",
    "            return {'audio': None, 'text': None}\n",
    "        audio_file, audio_content = self.parse_line(self.json_data[idx])\n",
    "        waveform, sample_rate = torchaudio.load(self.get_wav(audio_file))\n",
    "        waveform = waveform\n",
    "        if sample_rate != self.sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform, sample_rate, self.sample_rate)\n",
    "        sample = {'audio': waveform, 'text': audio_content}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def parse_line(self, line):\n",
    "        return line['file'], line['text']\n",
    "\n",
    "    def get_wav(self, file_name):\n",
    "        path = self.data_path+'audio_files/'+file_name[0]+'/'+file_name[:2]+'/'+file_name\n",
    "        return path\n",
    "\n",
    "    def split(self, split_ratio=None, seed=42):\n",
    "        audio_dataset = self\n",
    "        size = len(audio_dataset)\n",
    "        my_split_ratio = self.split_ratio if split_ratio is None else split_ratio\n",
    "        lengths = [(i*size)//sum(my_split_ratio) for i in my_split_ratio]\n",
    "        lengths[-1] = size - sum(lengths[:-1])\n",
    "        split_dataset = random_split(audio_dataset, lengths, generator=torch.Generator().manual_seed(seed))\n",
    "        return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 50648 test_set: 254\n",
      "torch.Size([8, 176636]) torch.Size([8, 102])\n",
      "torch.Size([8, 145909]) torch.Size([8, 94])\n",
      "torch.Size([8, 139198]) torch.Size([8, 92])\n",
      "torch.Size([8, 140152]) torch.Size([8, 94])\n",
      "torch.Size([8, 151359]) torch.Size([8, 98])\n",
      "torch.Size([8, 130548]) torch.Size([8, 97])\n",
      "torch.Size([8, 182392]) torch.Size([8, 108])\n",
      "torch.Size([7, 152315]) torch.Size([7, 101])\n",
      "torch.Size([8, 176638]) torch.Size([8, 92])\n",
      "torch.Size([7, 161280]) torch.Size([7, 88])\n",
      "torch.Size([8, 168951]) torch.Size([8, 112])\n",
      "torch.Size([8, 169595]) torch.Size([8, 106])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = PrimeWordsDataset('./data/primewords_md_2018_set1/')\n",
    "    batch_size = 8\n",
    "    train_set, test_set = dataset.split([1000, 5])\n",
    "    k_size = 5 # kernel size for audio encoder\n",
    "    from pypinyin import lazy_pinyin\n",
    "    def chinese2pinyin(text):\n",
    "        pinyin = lazy_pinyin(text, strict=True,errors=lambda x: u'')\n",
    "        pinyin = [i for i in '|'.join(pinyin)]\n",
    "        return pinyin\n",
    "    from utils.helper import get_labels\n",
    "    from utils.dataset import LoaderGenerator\n",
    "    labels = get_labels()\n",
    "    loaderGenerator = LoaderGenerator(labels, chinese2pinyin, k_size)\n",
    "    train_loader = loaderGenerator.dataloader(train_set, batch_size)\n",
    "    test_loader = loaderGenerator.dataloader(test_set, batch_size) # without backprop, can use larger batch\n",
    "    print('train_set:', len(train_set), 'test_set:',len(test_set))\n",
    "    steps = 10\n",
    "    for i_batch, sample_batched in enumerate(test_loader):\n",
    "        print(sample_batched['audio'].shape, sample_batched['target'].shape)\n",
    "        # for i in sample_batched['audio']:\n",
    "        #     print(i.shape)\n",
    "        if steps < 0:\n",
    "            break\n",
    "        steps -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PrimeWordsDataset('./data/primewords_md_2018_set1/')\n",
    "lens = [dataset[i]['audio'].shape[-1] for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -9.1553e-05,\n",
       "          -6.1035e-05,  3.0518e-05]]),\n",
       " 'text': '黎正训 黎安理 黎恂 黎恺 黎庶焘等都在那里任过教'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.save('./audio-temp.wav', dataset[1]['audio'], 16000)\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens2 = [dataset[i+500]['audio'].shape[-1] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens+lens2, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'li|zheng|xun|-|li|an|li|-|li|xun|-|li|kai|-|li|shu|dao|deng|dou|zai|na|li|ren|guo|jiao|-'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chinese2pinyin(text):\n",
    "    pinyin = lazy_pinyin(text, strict=True,errors=lambda x: u'-')\n",
    "    pinyin = [i for i in '|'.join(pinyin)]\n",
    "    return pinyin\n",
    "\n",
    "''.join(chinese2pinyin('黎正训 黎安理 黎恂 黎恺 黎庶焘等都在那里任过教 '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3322949f56cb4db99427e05ed2d4a87f0497ffa3e41dd81b99d577253bd3be5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
